{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq_labeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+qHIF0/HWKWsXZYMq5YOz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lindeberg25/layoutlm/blob/master/Seq_labeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzlDS0aOCDq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1f45f94c-30ef-4aa6-bcf4-575268244613"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AEPmIACjwrmsSyM91DsLqmqmGf5hfqmfSFl39jQxuSYVSDCmbo4lgI\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ68DSY2AzQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73baed62-77c9-434b-85d5-8af76dbd4002"
      },
      "source": [
        "!pip install transformers==2.9.0 tensorboardX==2.0 lxml==4.5.1 seqeval==0.0.12 Pillow==7.1.2 flake8==3.8.2 isort==4.3.21 black==19.10b0 pre-commit==2.4.0\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.9.0\n",
            "  Using cached transformers-2.9.0-py3-none-any.whl (635 kB)\n",
            "Collecting tensorboardX==2.0\n",
            "  Using cached tensorboardX-2.0-py2.py3-none-any.whl (195 kB)\n",
            "Collecting lxml==4.5.1\n",
            "  Using cached lxml-4.5.1-cp36-cp36m-manylinux1_x86_64.whl (5.5 MB)\n",
            "Processing /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68/seqeval-0.0.12-cp36-none-any.whl\n",
            "Collecting Pillow==7.1.2\n",
            "  Using cached Pillow-7.1.2-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "Collecting flake8==3.8.2\n",
            "  Using cached flake8-3.8.2-py2.py3-none-any.whl (72 kB)\n",
            "Collecting isort==4.3.21\n",
            "  Using cached isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
            "Collecting black==19.10b0\n",
            "  Using cached black-19.10b0-py36-none-any.whl (97 kB)\n",
            "Collecting pre-commit==2.4.0\n",
            "  Using cached pre_commit-2.4.0-py2.py3-none-any.whl (171 kB)\n",
            "Collecting tokenizers==0.7.0\n",
            "  Using cached tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0) (1.19.1)\n",
            "Collecting dataclasses; python_version < \"3.7\"\n",
            "  Downloading dataclasses-0.7-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0) (4.48.2)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Using cached sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0) (2.24.0)\n",
            "Processing /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45/sacremoses-0.0.43-cp36-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from tensorboardX==2.0) (1.15.0)\n",
            "Collecting protobuf>=3.8.0\n",
            "  Downloading protobuf-3.13.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 12.7 MB/s \n",
            "\u001b[?25hCollecting Keras>=2.2.4\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Using cached mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pycodestyle<2.7.0,>=2.6.0a1\n",
            "  Using cached pycodestyle-2.6.0-py2.py3-none-any.whl (41 kB)\n",
            "Collecting pyflakes<2.3.0,>=2.2.0\n",
            "  Using cached pyflakes-2.2.0-py2.py3-none-any.whl (66 kB)\n",
            "Collecting importlib-metadata; python_version < \"3.8\"\n",
            "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting appdirs\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting typed-ast>=1.4.0\n",
            "  Using cached typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737 kB)\n",
            "Collecting pathspec<1,>=0.6\n",
            "  Using cached pathspec-0.8.0-py2.py3-none-any.whl (28 kB)\n",
            "Collecting click>=6.5\n",
            "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting attrs>=18.1.0\n",
            "  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting toml>=0.9.4\n",
            "  Downloading toml-0.10.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Using cached nodeenv-1.5.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Using cached identify-1.5.0-py2.py3-none-any.whl (97 kB)\n",
            "Processing /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd/PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Using cached virtualenv-20.0.31-py2.py3-none-any.whl (4.9 MB)\n",
            "Collecting importlib-resources; python_version < \"3.7\"\n",
            "  Using cached importlib_resources-3.0.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting cfgv>=2.0.0\n",
            "  Using cached cfgv-3.2.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0) (1.25.10)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0) (2020.6.20)\n",
            "Collecting joblib\n",
            "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
            "\u001b[K     |████████████████████████████████| 300 kB 24.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX==2.0) (49.6.0.post20200814)\n",
            "Collecting h5py\n",
            "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.9 MB/s \n",
            "\u001b[?25hCollecting scipy>=0.14\n",
            "  Downloading scipy-1.5.2-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 97.3 MB/s \n",
            "\u001b[?25hCollecting zipp>=0.5\n",
            "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Using cached distlib-0.3.1-py2.py3-none-any.whl (335 kB)\n",
            "Installing collected packages: tokenizers, dataclasses, filelock, regex, sentencepiece, joblib, click, sacremoses, transformers, protobuf, tensorboardX, lxml, h5py, pyyaml, scipy, Keras, seqeval, Pillow, mccabe, pycodestyle, pyflakes, zipp, importlib-metadata, flake8, isort, appdirs, typed-ast, pathspec, attrs, toml, black, nodeenv, identify, importlib-resources, distlib, virtualenv, cfgv, pre-commit\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.2.0\n",
            "    Uninstalling Pillow-7.2.0:\n",
            "      Successfully uninstalled Pillow-7.2.0\n",
            "Successfully installed Keras-2.4.3 Pillow-7.1.2 appdirs-1.4.4 attrs-20.2.0 black-19.10b0 cfgv-3.2.0 click-7.1.2 dataclasses-0.7 distlib-0.3.1 filelock-3.0.12 flake8-3.8.2 h5py-2.10.0 identify-1.5.0 importlib-metadata-1.7.0 importlib-resources-3.0.0 isort-4.3.21 joblib-0.16.0 lxml-4.5.1 mccabe-0.6.1 nodeenv-1.5.0 pathspec-0.8.0 pre-commit-2.4.0 protobuf-3.13.0 pycodestyle-2.6.0 pyflakes-2.2.0 pyyaml-5.3.1 regex-2020.7.14 sacremoses-0.0.43 scipy-1.5.2 sentencepiece-0.1.91 seqeval-0.0.12 tensorboardX-2.0 tokenizers-0.7.0 toml-0.10.1 transformers-2.9.0 typed-ast-1.4.1 virtualenv-20.0.31 zipp-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x29uOMMPEEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6fccbae-7e51-4ed9-c9ee-9329f9949e9f"
      },
      "source": [
        "%env PYTHONPATH="
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f-9f_xoRRwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7c7bb71-ce07-4945-9007-d837c0aad418"
      },
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-09-09 23:21:36--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2020-09-09 23:21:36--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 63.8M 1s\n",
            "    50K .......... .......... .......... .......... ..........  0% 5.65M 5s\n",
            "   100K .......... .......... .......... .......... ..........  0% 5.76M 7s\n",
            "   150K .......... .......... .......... .......... ..........  0% 5.71M 8s\n",
            "   200K .......... .......... .......... .......... ..........  0%  151M 6s\n",
            "   250K .......... .......... .......... .......... ..........  0%  187M 5s\n",
            "   300K .......... .......... .......... .......... ..........  0% 6.27M 6s\n",
            "   350K .......... .......... .......... .......... ..........  0%  150M 5s\n",
            "   400K .......... .......... .......... .......... ..........  0%  221M 4s\n",
            "   450K .......... .......... .......... .......... ..........  0% 84.0M 4s\n",
            "   500K .......... .......... .......... .......... ..........  0%  180M 4s\n",
            "   550K .......... .......... .......... .......... ..........  1%  117M 3s\n",
            "   600K .......... .......... .......... .......... ..........  1%  131M 3s\n",
            "   650K .......... .......... .......... .......... ..........  1%  133M 3s\n",
            "   700K .......... .......... .......... .......... ..........  1%  178M 3s\n",
            "   750K .......... .......... .......... .......... ..........  1% 8.70M 3s\n",
            "   800K .......... .......... .......... .......... ..........  1%  201M 3s\n",
            "   850K .......... .......... .......... .......... ..........  1%  188M 3s\n",
            "   900K .......... .......... .......... .......... ..........  1%  110M 3s\n",
            "   950K .......... .......... .......... .......... ..........  1% 78.0M 3s\n",
            "  1000K .......... .......... .......... .......... ..........  1%  195M 2s\n",
            "  1050K .......... .......... .......... .......... ..........  1%  125M 2s\n",
            "  1100K .......... .......... .......... .......... ..........  2%  133M 2s\n",
            "  1150K .......... .......... .......... .......... ..........  2% 91.7M 2s\n",
            "  1200K .......... .......... .......... .......... ..........  2%  123M 2s\n",
            "  1250K .......... .......... .......... .......... ..........  2%  187M 2s\n",
            "  1300K .......... .......... .......... .......... ..........  2%  112M 2s\n",
            "  1350K .......... .......... .......... .......... ..........  2%  114M 2s\n",
            "  1400K .......... .......... .......... .......... ..........  2%  110M 2s\n",
            "  1450K .......... .......... .......... .......... ..........  2%  182M 2s\n",
            "  1500K .......... .......... .......... .......... ..........  2% 16.2M 2s\n",
            "  1550K .......... .......... .......... .......... ..........  2%  146M 2s\n",
            "  1600K .......... .......... .......... .......... ..........  2%  197M 2s\n",
            "  1650K .......... .......... .......... .......... ..........  2%  188M 2s\n",
            "  1700K .......... .......... .......... .......... ..........  3%  140M 2s\n",
            "  1750K .......... .......... .......... .......... ..........  3%  172M 2s\n",
            "  1800K .......... .......... .......... .......... ..........  3%  185M 2s\n",
            "  1850K .......... .......... .......... .......... ..........  3%  171M 2s\n",
            "  1900K .......... .......... .......... .......... ..........  3%  177M 2s\n",
            "  1950K .......... .......... .......... .......... ..........  3%  146M 1s\n",
            "  2000K .......... .......... .......... .......... ..........  3%  190M 1s\n",
            "  2050K .......... .......... .......... .......... ..........  3%  167M 1s\n",
            "  2100K .......... .......... .......... .......... ..........  3%  181M 1s\n",
            "  2150K .......... .......... .......... .......... ..........  3%  153M 1s\n",
            "  2200K .......... .......... .......... .......... ..........  3%  170M 1s\n",
            "  2250K .......... .......... .......... .......... ..........  4% 60.1M 1s\n",
            "  2300K .......... .......... .......... .......... ..........  4%  156M 1s\n",
            "  2350K .......... .......... .......... .......... ..........  4%  146M 1s\n",
            "  2400K .......... .......... .......... .......... ..........  4%  178M 1s\n",
            "  2450K .......... .......... .......... .......... ..........  4%  165M 1s\n",
            "  2500K .......... .......... .......... .......... ..........  4%  170M 1s\n",
            "  2550K .......... .......... .......... .......... ..........  4%  144M 1s\n",
            "  2600K .......... .......... .......... .......... ..........  4%  160M 1s\n",
            "  2650K .......... .......... .......... .......... ..........  4%  146M 1s\n",
            "  2700K .......... .......... .......... .......... ..........  4%  180M 1s\n",
            "  2750K .......... .......... .......... .......... ..........  4%  175M 1s\n",
            "  2800K .......... .......... .......... .......... ..........  4%  164M 1s\n",
            "  2850K .......... .......... .......... .......... ..........  5%  183M 1s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  173M 1s\n",
            "  2950K .......... .......... .......... .......... ..........  5%  136M 1s\n",
            "  3000K .......... .......... .......... .......... ..........  5%  165M 1s\n",
            "  3050K .......... .......... .......... .......... ..........  5%  181M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  5%  167M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  5%  139M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  5%  187M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  5%  147M 1s\n",
            "  3300K .......... .......... .......... .......... ..........  5%  145M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  164M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  164M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  150M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6%  184M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  149M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  144M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  176M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  174M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6%  143M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6%  168M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6%  176M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6%  173M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7%  131M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7%  179M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7%  180M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7%  155M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7%  154M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7%  163M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7%  144M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7%  175M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7%  158M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7%  167M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7%  184M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7%  169M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8%  152M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8%  181M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8%  179M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8%  160M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8%  164M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8%  169M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8%  170M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8%  194M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8%  150M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8%  176M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8%  184M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9%  177M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9%  145M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9%  181M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  180M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  155M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  155M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  175M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  196M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  139M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9%  152M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  167M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9%  163M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  179M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  176M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  174M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  165M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  188M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  150M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10%  175M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  193M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  172M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10%  153M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  182M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  188M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  187M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11%  131M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11%  188M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11%  196M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11%  165M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11%  162M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11%  189M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11%  178M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11%  172M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11%  149M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11%  165M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12%  144M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12%  190M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12%  156M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12%  199M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12%  147M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12%  190M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12%  163M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12%  177M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12%  178M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12%  179M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12%  166M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13%  156M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13%  197M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13%  187M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13%  134M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13%  187M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13%  197M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  179M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  148M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  184M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  182M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  179M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14%  138M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14%  176M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  192M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14%  175M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  175M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  171M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  172M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  163M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14%  162M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14%  190M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14%  179M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  164M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  160M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15%  181M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15%  189M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15%  184M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 15%  147M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  156M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  193M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  193M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 15%  167M 1s\n",
            "  9000K .......... .......... .......... .......... .......... 15%  162M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  163M 1s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  195M 1s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  140M 1s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  199M 1s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  187M 1s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  166M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 16%  149M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  183M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  177M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 16%  178M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 16%  163M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  186M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 16%  184M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  144M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  160M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 17%  195M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 17%  174M 0s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  182M 0s\n",
            "  9950K .......... .......... .......... .......... .......... 17%  170M 0s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  197M 0s\n",
            " 10050K .......... .......... .......... .......... .......... 17%  199M 0s\n",
            " 10100K .......... .......... .......... .......... .......... 17%  199M 0s\n",
            " 10150K .......... .......... .......... .......... .......... 17%  185M 0s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  177M 0s\n",
            " 10250K .......... .......... .......... .......... .......... 18%  166M 0s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  152M 0s\n",
            " 10350K .......... .......... .......... .......... .......... 18%  150M 0s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  160M 0s\n",
            " 10450K .......... .......... .......... .......... .......... 18%  191M 0s\n",
            " 10500K .......... .......... .......... .......... .......... 18%  195M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  152M 0s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  185M 0s\n",
            " 10650K .......... .......... .......... .......... .......... 18%  189M 0s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  218M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  160M 0s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  182M 0s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  202M 0s\n",
            " 10900K .......... .......... .......... .......... .......... 19%  193M 0s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  154M 0s\n",
            " 11000K .......... .......... .......... .......... .......... 19%  205M 0s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  199M 0s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  202M 0s\n",
            " 11150K .......... .......... .......... .......... .......... 19%  144M 0s\n",
            " 11200K .......... .......... .......... .......... .......... 19%  192M 0s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  215M 0s\n",
            " 11300K .......... .......... .......... .......... .......... 19%  168M 0s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  191M 0s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  212M 0s\n",
            " 11450K .......... .......... .......... .......... .......... 20%  219M 0s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  207M 0s\n",
            " 11550K .......... .......... .......... .......... .......... 20%  164M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  222M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 20%  218M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 20%  222M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 20%  165M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  199M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  182M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 20%  137M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  142M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  168M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  137M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  176M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  143M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  162M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 21%  183M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 21%  181M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 21%  152M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 21%  163M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  172M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 21%  193M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  165M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  160M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 22%  184M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  175M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  146M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 22%  194M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 22%  191M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 22%  177M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 22%  169M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 22%  180M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 22%  190M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  157M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  160M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  186M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 23%  194M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  155M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 23%  146M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 23%  194M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  177M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  194M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 23%  158M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  197M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  159M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  169M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 24%  155M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  170M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  172M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  190M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  154M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  188M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  171M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  207M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 24%  178M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 24%  212M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  222M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  208M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  161M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  182M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  196M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  194M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  183M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 25%  195M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  199M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  190M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  148M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  198M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  193M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26%  195M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26%  162M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26%  195M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26%  195M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26%  198M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26%  151M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  195M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  193M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26%  186M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26%  167M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  198M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  198M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27%  181M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27%  161M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  195M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  164M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27%  140M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27%  149M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27%  161M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  151M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27%  163M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28%  128M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28%  141M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  171M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28%  156M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28%  126M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  192M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28%  192M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28%  181M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28%  156M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28%  192M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28%  192M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28%  180M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29%  177M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29%  188M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29%  197M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29%  176M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29%  160M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29%  195M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29%  189M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29%  187M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  174M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29%  195M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  183M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  168M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30%  135M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30%  183M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  184M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  195M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  172M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  183M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30%  188M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  195M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30%  160M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  181M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  190M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  195M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31%  176M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31%  175M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31%  195M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  193M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31%  154M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  172M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31%  166M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  166M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  136M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  160M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  158M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  150M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  139M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  165M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  176M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32%  197M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32%  144M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32%  169M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32%  185M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32%  191M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32%  162M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33%  174M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33%  192M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33%  196M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  175M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33%  140M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33%  200M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33%  182M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33%  138M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33%  192M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  297M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33%  307M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  290M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34%  207M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34%  191M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34%  191M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34%  132M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  163M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34%  190M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34%  195M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34%  163M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34% 70.6M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  157M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34%  156M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35%  138M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  169M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  156M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35%  176M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  174M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35%  169M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  196M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  187M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35%  158M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  171M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35%  190M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  177M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  147M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36%  194M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36%  194M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  161M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36%  135M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36%  197M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  196M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36%  157M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36%  158M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36%  182M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  193M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37%  181M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37%  163M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37%  212M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37%  172M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37%  163M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37%  166M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37%  172M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  160M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37%  179M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37%  155M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  194M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38%  237M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38%  304M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38%  280M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38%  306M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38%  314M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38%  191M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38%  152M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38%  174M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38%  157M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38%  173M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38%  166M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38%  191M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39%  161M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39%  171M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39%  160M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39%  179M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39%  171M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39%  162M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39%  176M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39%  195M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39%  205M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39%  187M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39%  131M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40%  161M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40%  165M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40%  185M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40%  134M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40%  169M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  201M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40%  158M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40%  166M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  198M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  199M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  160M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40%  174M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41%  196M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41%  149M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41%  182M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  164M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  194M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41%  180M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  186M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41%  171M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41%  174M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41%  151M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41%  168M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42%  131M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42%  171M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42%  188M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  194M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  160M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  176M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42%  184M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42%  196M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42%  152M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  197M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  193M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  154M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  137M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  173M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43%  211M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  188M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  161M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43%  181M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43%  178M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43%  164M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  185M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  187M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  200M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44%  191M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  159M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44%  187M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44%  172M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  167M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44%  149M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  163M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  197M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44%  182M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  126M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  163M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  186M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45%  175M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45%  154M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45%  185M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45%  207M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  180M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45%  133M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  185M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45%  176M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  173M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45%  181M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  185M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  189M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46%  175M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46%  146M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46%  179M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  173M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  191M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  171M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46%  198M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46%  172M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46%  193M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46%  143M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  161M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  167M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  182M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47%  166M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47%  165M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  192M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  195M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  141M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  186M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47%  189M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47%  196M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47%  156M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48%  185M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48%  155M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48%  174M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48%  155M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48%  195M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48%  196M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48%  174M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48%  173M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  196M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48%  190M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48%  182M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  163M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49%  190M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49%  197M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  178M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49%  172M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49%  195M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  186M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  186M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  164M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49%  193M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  174M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50%  178M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  162M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  156M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  154M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  164M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  135M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50%  158M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50%  164M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  160M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50%  137M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  163M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  167M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51%  162M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51%  162M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  198M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  193M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  166M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51%  179M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  190M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  188M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51%  187M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  162M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  191M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52%  184M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52%  196M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52%  175M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52%  195M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52%  183M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52%  194M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52%  147M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52%  161M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52%  168M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  194M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  172M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  150M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  162M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  171M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  126M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  161M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53%  173M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53%  171M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53%  156M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  183M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  198M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  174M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  164M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  192M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  193M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54%  185M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54%  178M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54%  221M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54%  217M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54%  182M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54%  173M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  220M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54%  220M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54%  187M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  182M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  206M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  190M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  172M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  148M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  195M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  177M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55%  196M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55%  172M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55%  185M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55%  188M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  171M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56%  137M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  149M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  168M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56%  175M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  145M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56%  200M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56%  178M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  202M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  156M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  205M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  197M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57%  205M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57%  168M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  206M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57%  203M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  208M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  165M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57%  218M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  197M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  206M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57%  172M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  144M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57%  206M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  205M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  150M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  174M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58%  168M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  156M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  190M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  321M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  291M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  247M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58%  127M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  202M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  194M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  162M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59%  154M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  196M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  178M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  164M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  180M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  219M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59%  212M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59%  189M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59%  199M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59%  219M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  220M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60%  199M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  161M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  206M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  223M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60%  202M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  194M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60%  177M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  181M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60%  185M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  151M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  206M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  209M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  178M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61%  176M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61%  214M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  205M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61%  188M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61%  156M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61%  154M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  149M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61%  189M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61%  169M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62%  181M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62%  174M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  182M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62%  169M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  187M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  217M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  217M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62%  199M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62%  193M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62%  220M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  225M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63%  220M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63%  304M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63%  191M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  213M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63%  191M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  210M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63%  162M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63%  191M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63%  145M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  191M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  187M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64%  171M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64%  164M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64%  176M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  218M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  208M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64%  165M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  172M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64%  204M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  205M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  165M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  196M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  232M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65%  231M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65%  169M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65%  190M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  223M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  218M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65%  193M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65%  198M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  201M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  211M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  173M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  188M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  204M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66%  198M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66%  196M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  180M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  201M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  175M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  156M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66% 60.8M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  185M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  190M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  170M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  184M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67%  158M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  165M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67%  131M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  164M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67%  166M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67%  167M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67%  162M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  163M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  199M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  192M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  151M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  223M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  217M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  218M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  175M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  218M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68%  222M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  186M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68%  158M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  202M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  204M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  204M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  140M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69%  190M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69%  189M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  177M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  173M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  210M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  207M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69%  180M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69%  161M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  178M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  211M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69%  182M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70%  165M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  221M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70%  185M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  169M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  175M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  218M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70%  195M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  184M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  164M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  205M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70%  181M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71%  188M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  185M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  200M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  192M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  211M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  185M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  220M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71%  204M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  173M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  148M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71%  181M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  171M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  193M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72%  149M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  206M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  181M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  225M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  174M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  166M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72%  194M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  186M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72%  139M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  175M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73%  200M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  209M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  178M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73%  189M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  207M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  202M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73%  164M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  152M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73%  167M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  197M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73%  149M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  186M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74%  161M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  203M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  162M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74%  216M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74%  189M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74%  212M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74%  154M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74%  201M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  199M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  191M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  166M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  205M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  175M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  166M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75%  152M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75%  184M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  203M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75%  154M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75%  151M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75%  213M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  189M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  214M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76%  203M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76%  218M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  203M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  187M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  152M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76%  176M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  169M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  193M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  168M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  193M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  202M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76%  204M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  183M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77%  193M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77%  187M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  219M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  193M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  226M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  197M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  219M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  183M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  189M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  161M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  192M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78%  184M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  209M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78%  198M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78%  195M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78%  163M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  206M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78%  178M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  196M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  179M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78%  190M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  216M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  214M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  161M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  157M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79%  223M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79%  204M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  169M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  185M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  223M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  193M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79%  185M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  170M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  200M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  223M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  160M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80%  187M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  190M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  223M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  184M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80%  204M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80%  216M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  160M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80%  155M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81%  191M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  221M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  222M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81%  158M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81%  210M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  227M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  215M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81%  197M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  203M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81%  172M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  180M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81%  144M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  215M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82%  177M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  197M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  147M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  192M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  200M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82%  217M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  166M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  187M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82%  170M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82%  182M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83%  188M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83%  222M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  188M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  209M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  148M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  205M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83%  173M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  156M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  172M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  219M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83%  215M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  225M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84%  165M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  196M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84%  206M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84%  189M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84%  172M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84%  207M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84%  214M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  166M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84%  138M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84%  206M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84%  191M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85%  174M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85%  154M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85%  169M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85%  164M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85%  216M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85%  176M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  208M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  183M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85%  204M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85%  177M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85%  217M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85%  196M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86%  217M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86%  182M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86%  214M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86%  168M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86%  191M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86%  195M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  192M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86%  179M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  201M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86%  169M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86%  175M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  195M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  204M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  184M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  193M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87%  197M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87%  185M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  167M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  164M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87%  177M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87%  204M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87%  194M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  200M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  221M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  218M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  183M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  202M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  218M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  222M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  197M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88%  212M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88%  188M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88%  186M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88%  152M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89%  168M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89%  182M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89%  204M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  186M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89%  166M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89%  201M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89%  204M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  147M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  177M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89%  188M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  206M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  181M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  220M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90%  205M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90%  221M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  170M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  184M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90%  154M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90%  165M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  171M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  220M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90%  221M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  219M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91%  160M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  207M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  234M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  235M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91%  198M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  203M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  176M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91%  181M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91%  169M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  207M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  220M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  220M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  179M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92%  205M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  203M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92%  175M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  128M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92%  199M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92%  190M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  177M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92%  157M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  181M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92%  206M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  173M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93%  163M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93%  168M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93%  176M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93%  152M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93%  177M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93%  194M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93%  186M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  192M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93%  174M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93%  201M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94%  187M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  206M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  181M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  145M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94%  192M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  182M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  168M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  190M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  201M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  211M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94%  197M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95%  155M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95%  178M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95%  197M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  170M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  166M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  181M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  192M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95%  166M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95%  196M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  209M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  205M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  127M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  183M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  205M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  173M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96%  168M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  198M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  185M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  173M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  159M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  199M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  186M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  193M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  164M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  183M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  184M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97%  166M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97%  180M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97%  203M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97%  199M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  179M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  171M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  197M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  197M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  198M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  169M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  207M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98%  180M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  181M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98%  176M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98%  200M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98%  178M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98%  195M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98%  171M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  202M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98%  187M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  222M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  178M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  204M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  188M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  217M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  182M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  225M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99% 69.4M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  210M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  191M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  184M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100%  211M=0.4s\n",
            "\n",
            "2020-09-09 23:21:36 (156 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ELnj47TC1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "338c7695-b986-4cb3-bb77-3eccf6d85319"
      },
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    sqlite-3.33.0              |       h62c20be_0         2.0 MB\n",
            "    pycosat-0.6.3              |   py36h7b6447c_0         107 KB\n",
            "    python-3.6.12              |       hcff3b4d_2        34.0 MB\n",
            "    pycparser-2.20             |             py_2          94 KB\n",
            "    ca-certificates-2020.7.22  |                0         132 KB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    cffi-1.14.2                |   py36he30daa8_0         228 KB\n",
            "    libedit-3.1.20191231       |       h14c3975_1         121 KB\n",
            "    openssl-1.1.1g             |       h7b6447c_0         3.8 MB\n",
            "    pysocks-1.7.1              |           py36_0          30 KB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    readline-8.0               |       h7b6447c_0         428 KB\n",
            "    ncurses-6.2                |       he6710b0_1         1.1 MB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    idna-2.10                  |             py_0          56 KB\n",
            "    urllib3-1.25.10            |             py_0          93 KB\n",
            "    chardet-3.0.4              |        py36_1003         197 KB\n",
            "    pip-20.2.2                 |           py36_0         2.0 MB\n",
            "    pyopenssl-19.1.0           |             py_1          47 KB\n",
            "    cryptography-3.1           |   py36h1ba5d50_0         622 KB\n",
            "    ruamel_yaml-0.15.87        |   py36h7b6447c_1         256 KB\n",
            "    conda-4.8.4                |           py36_0         3.0 MB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    ld_impl_linux-64-2.33.1    |       h53a641e_7         645 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    certifi-2020.6.20          |           py36_0         160 KB\n",
            "    brotlipy-0.7.0             |py36h7b6447c_1000         348 KB\n",
            "    setuptools-49.6.0          |           py36_0         927 KB\n",
            "    conda-package-handling-1.6.1|   py36h7b6447c_0         886 KB\n",
            "    wheel-0.35.1               |             py_0          36 KB\n",
            "    six-1.15.0                 |             py_0          13 KB\n",
            "    requests-2.24.0            |             py_0          54 KB\n",
            "    tqdm-4.48.2                |             py_0          63 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        67.5 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:          0.1-main               \n",
            "    brotlipy:               0.7.0-py36h7b6447c_1000\n",
            "    conda-package-handling: 1.6.1-py36h7b6447c_0   \n",
            "    ld_impl_linux-64:       2.33.1-h53a641e_7      \n",
            "    tqdm:                   4.48.2-py_0            \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2020.7.22-0            \n",
            "    certifi:                2018.4.16-py36_0        --> 2020.6.20-py36_0       \n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.2-py36he30daa8_0  \n",
            "    chardet:                3.0.4-py36h0f667ec_1    --> 3.0.4-py36_1003        \n",
            "    conda:                  4.5.4-py36_0            --> 4.8.4-py36_0           \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 3.1-py36h1ba5d50_0     \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 2.10-py_0              \n",
            "    libedit:                3.1.20170329-h6b74fdf_2 --> 3.1.20191231-h14c3975_1\n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2         \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0       \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0       \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.2-he6710b0_1         \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1g-h7b6447c_0      \n",
            "    pip:                    10.0.1-py36_0           --> 20.2.2-py36_0          \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py36h7b6447c_0   \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.20-py_2              \n",
            "    pyopenssl:              18.0.0-py36_0           --> 19.1.0-py_1            \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py36_0           \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.12-hcff3b4d_2      \n",
            "    readline:               7.0-ha6073c6_4          --> 8.0-h7b6447c_0         \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.24.0-py_0            \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.87-py36h7b6447c_1 \n",
            "    setuptools:             39.2.0-py36_0           --> 49.6.0-py36_0          \n",
            "    six:                    1.11.0-py36h372c433_1   --> 1.15.0-py_0            \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.33.0-h62c20be_0      \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.10-hbc83047_0      \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.25.10-py_0           \n",
            "    wheel:                  0.31.1-py36_0           --> 0.35.1-py_0            \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0       \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0       \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3      \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  asn1crypto-0.24.0-py36_0\n",
            "  conda-env-2.6.0-h36134e3_1\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rxz-5.2.5             |  438 KB |            |   0% \rxz-5.2.5             |  438 KB | #########3 |  93% \rxz-5.2.5             |  438 KB | ########## | 100% \n",
            "\rsqlite-3.33.0        |  2.0 MB |            |   0% \rsqlite-3.33.0        |  2.0 MB | ########   |  81% \rsqlite-3.33.0        |  2.0 MB | ########## | 100% \n",
            "\rpycosat-0.6.3        |  107 KB |            |   0% \rpycosat-0.6.3        |  107 KB | ########## | 100% \n",
            "\rpython-3.6.12        | 34.0 MB |            |   0% \rpython-3.6.12        | 34.0 MB | ##8        |  28% \rpython-3.6.12        | 34.0 MB | ######8    |  69% \rpython-3.6.12        | 34.0 MB | ########7  |  87% \rpython-3.6.12        | 34.0 MB | ########## | 100% \n",
            "\rpycparser-2.20       |   94 KB |            |   0% \rpycparser-2.20       |   94 KB | ########## | 100% \n",
            "\rca-certificates-2020 |  132 KB |            |   0% \rca-certificates-2020 |  132 KB | ########## | 100% \n",
            "\rzlib-1.2.11          |  120 KB |            |   0% \rzlib-1.2.11          |  120 KB | ########## | 100% \n",
            "\rcffi-1.14.2          |  228 KB |            |   0% \rcffi-1.14.2          |  228 KB | ########## | 100% \n",
            "\rlibedit-3.1.20191231 |  121 KB |            |   0% \rlibedit-3.1.20191231 |  121 KB | ########## | 100% \n",
            "\ropenssl-1.1.1g       |  3.8 MB |            |   0% \ropenssl-1.1.1g       |  3.8 MB | #######7   |  78% \ropenssl-1.1.1g       |  3.8 MB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   30 KB |            |   0% \rpysocks-1.7.1        |   30 KB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n",
            "\rlibstdcxx-ng-9.1.0   |  4.0 MB |            |   0% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #######6   |  77% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #########4 |  95% \rlibstdcxx-ng-9.1.0   |  4.0 MB | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    |    3 KB |            |   0% \r_libgcc_mutex-0.1    |    3 KB | ########## | 100% \n",
            "\rreadline-8.0         |  428 KB |            |   0% \rreadline-8.0         |  428 KB | ########## | 100% \n",
            "\rncurses-6.2          |  1.1 MB |            |   0% \rncurses-6.2          |  1.1 MB | #######8   |  78% \rncurses-6.2          |  1.1 MB | #########9 |  99% \rncurses-6.2          |  1.1 MB | ########## | 100% \n",
            "\rtk-8.6.10            |  3.2 MB |            |   0% \rtk-8.6.10            |  3.2 MB | #######8   |  79% \rtk-8.6.10            |  3.2 MB | ########## | 100% \n",
            "\ridna-2.10            |   56 KB |            |   0% \ridna-2.10            |   56 KB | ########## | 100% \n",
            "\rurllib3-1.25.10      |   93 KB |            |   0% \rurllib3-1.25.10      |   93 KB | ########## | 100% \n",
            "\rchardet-3.0.4        |  197 KB |            |   0% \rchardet-3.0.4        |  197 KB | ########## | 100% \n",
            "\rpip-20.2.2           |  2.0 MB |            |   0% \rpip-20.2.2           |  2.0 MB | #######7   |  78% \rpip-20.2.2           |  2.0 MB | ########## | 100% \n",
            "\rpyopenssl-19.1.0     |   47 KB |            |   0% \rpyopenssl-19.1.0     |   47 KB | ########## | 100% \n",
            "\rcryptography-3.1     |  622 KB |            |   0% \rcryptography-3.1     |  622 KB | ########   |  81% \rcryptography-3.1     |  622 KB | ########## | 100% \n",
            "\rruamel_yaml-0.15.87  |  256 KB |            |   0% \rruamel_yaml-0.15.87  |  256 KB | ########## | 100% \n",
            "\rconda-4.8.4          |  3.0 MB |            |   0% \rconda-4.8.4          |  3.0 MB | ########1  |  81% \rconda-4.8.4          |  3.0 MB | ########## | 100% \n",
            "\rlibgcc-ng-9.1.0      |  8.1 MB |            |   0% \rlibgcc-ng-9.1.0      |  8.1 MB | #######5   |  76% \rlibgcc-ng-9.1.0      |  8.1 MB | #########7 |  97% \rlibgcc-ng-9.1.0      |  8.1 MB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  645 KB |            |   0% \rld_impl_linux-64-2.3 |  645 KB | #########2 |  93% \rld_impl_linux-64-2.3 |  645 KB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\rcertifi-2020.6.20    |  160 KB |            |   0% \rcertifi-2020.6.20    |  160 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  348 KB |            |   0% \rbrotlipy-0.7.0       |  348 KB | ########## | 100% \n",
            "\rsetuptools-49.6.0    |  927 KB |            |   0% \rsetuptools-49.6.0    |  927 KB | ########1  |  81% \rsetuptools-49.6.0    |  927 KB | ########## | 100% \n",
            "\rconda-package-handli |  886 KB |            |   0% \rconda-package-handli |  886 KB | #########1 |  91% \rconda-package-handli |  886 KB | ########## | 100% \n",
            "\rwheel-0.35.1         |   36 KB |            |   0% \rwheel-0.35.1         |   36 KB | ########## | 100% \n",
            "\rsix-1.15.0           |   13 KB |            |   0% \rsix-1.15.0           |   13 KB | ########## | 100% \n",
            "\rrequests-2.24.0      |   54 KB |            |   0% \rrequests-2.24.0      |   54 KB | ########## | 100% \n",
            "\rtqdm-4.48.2          |   63 KB |            |   0% \rtqdm-4.48.2          |   63 KB | ########## | 100% \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZASbTiofT1Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path\n",
        "\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.6/site-packages\"))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OonIO5igVssX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aaeb4807-fd2b-41d4-c6c7-a6492039e0b3"
      },
      "source": [
        "!conda create -n layoutlm python=3.6 --yes"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/layoutlm\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    ca-certificates-2020.7.22  |                0         125 KB\n",
            "    certifi-2020.6.20          |           py36_0         156 KB\n",
            "    ld_impl_linux-64-2.33.1    |       h53a641e_7         568 KB\n",
            "    libedit-3.1.20191231       |       h14c3975_1         116 KB\n",
            "    libffi-3.3                 |       he6710b0_2          50 KB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         5.1 MB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         3.1 MB\n",
            "    ncurses-6.2                |       he6710b0_1         817 KB\n",
            "    openssl-1.1.1g             |       h7b6447c_0         2.5 MB\n",
            "    pip-20.2.2                 |           py36_0         1.8 MB\n",
            "    python-3.6.12              |       hcff3b4d_2        29.7 MB\n",
            "    readline-8.0               |       h7b6447c_0         356 KB\n",
            "    setuptools-49.6.0          |           py36_0         757 KB\n",
            "    sqlite-3.33.0              |       h62c20be_0         1.1 MB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.0 MB\n",
            "    wheel-0.35.1               |             py_0          37 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         341 KB\n",
            "    zlib-1.2.11                |       h7b6447c_3         103 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        49.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.7.22-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2020.6.20-py36_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20191231-h14c3975_1\n",
            "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1g-h7b6447c_0\n",
            "  pip                pkgs/main/linux-64::pip-20.2.2-py36_0\n",
            "  python             pkgs/main/linux-64::python-3.6.12-hcff3b4d_2\n",
            "  readline           pkgs/main/linux-64::readline-8.0-h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-49.6.0-py36_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.35.1-py_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "wheel-0.35.1         | 37 KB     | : 100% 1.0/1 [00:00<00:00,  8.64it/s]\n",
            "zlib-1.2.11          | 103 KB    | : 100% 1.0/1 [00:00<00:00, 15.47it/s]\n",
            "openssl-1.1.1g       | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  7.11it/s]\n",
            "readline-8.0         | 356 KB    | : 100% 1.0/1 [00:00<00:00, 17.92it/s]\n",
            "xz-5.2.5             | 341 KB    | : 100% 1.0/1 [00:00<00:00, 17.37it/s]\n",
            "libedit-3.1.20191231 | 116 KB    | : 100% 1.0/1 [00:00<00:00, 18.00it/s]\n",
            "ca-certificates-2020 | 125 KB    | : 100% 1.0/1 [00:00<00:00, 22.22it/s]\n",
            "certifi-2020.6.20    | 156 KB    | : 100% 1.0/1 [00:00<00:00, 14.17it/s]\n",
            "setuptools-49.6.0    | 757 KB    | : 100% 1.0/1 [00:00<00:00, 12.47it/s]\n",
            "ncurses-6.2          | 817 KB    | : 100% 1.0/1 [00:00<00:00,  4.10it/s]\n",
            "tk-8.6.10            | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  6.90it/s]\n",
            "pip-20.2.2           | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  6.68it/s]\n",
            "python-3.6.12        | 29.7 MB   | : 100% 1.0/1 [00:00<00:00,  1.02it/s]               \n",
            "_libgcc_mutex-0.1    | 3 KB      | : 100% 1.0/1 [00:00<00:00, 10.64it/s]\n",
            "sqlite-3.33.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 12.74it/s]\n",
            "libstdcxx-ng-9.1.0   | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  7.73it/s]\n",
            "ld_impl_linux-64-2.3 | 568 KB    | : 100% 1.0/1 [00:00<00:00, 13.35it/s]\n",
            "libffi-3.3           | 50 KB     | : 100% 1.0/1 [00:00<00:00, 17.97it/s]\n",
            "libgcc-ng-9.1.0      | 5.1 MB    | : 100% 1.0/1 [00:00<00:00,  4.23it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate layoutlm\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCQNBlykWCI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01628ef8-1429-4ae7-c9dc-fdf5abeaa096"
      },
      "source": [
        "%%bash\n",
        "source /usr/local/etc/profile.d/conda.sh\n",
        "conda activate layoutlm\n",
        "#conda install pytorch==1.6.0 cudatoolkit=10.1 -c pytorch --yes # código do github do artigo. Entretanto, apresenta incompatibilidades. \n",
        "#Abaixo o torch==1.5.0 é instalado  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/layoutlm\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit=10.1\n",
            "    - pytorch==1.6.0\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    cudatoolkit-10.1.243       |       h6bb024c_0       347.4 MB\n",
            "    intel-openmp-2020.2        |              254         786 KB\n",
            "    mkl-2020.2                 |              256       138.3 MB\n",
            "    mkl-service-2.3.0          |   py36he904b0f_0         219 KB\n",
            "    mkl_fft-1.1.0              |   py36h23d657b_0         144 KB\n",
            "    mkl_random-1.1.1           |   py36h0573a6f_0         327 KB\n",
            "    ninja-1.10.1               |   py36hfd86e86_0         1.4 MB\n",
            "    numpy-1.19.1               |   py36hbc911f0_0          21 KB\n",
            "    numpy-base-1.19.1          |   py36hfa32c7d_0         4.1 MB\n",
            "    pytorch-1.6.0              |py3.6_cuda10.1.243_cudnn7.6.3_0       516.3 MB  pytorch\n",
            "    six-1.15.0                 |             py_0          13 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:      1009.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.1.243-h6bb024c_0\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2020.2-254\n",
            "  mkl                pkgs/main/linux-64::mkl-2020.2-256\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.3.0-py36he904b0f_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.1.0-py36h23d657b_0\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.1.1-py36h0573a6f_0\n",
            "  ninja              pkgs/main/linux-64::ninja-1.10.1-py36hfd86e86_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.19.1-py36hbc911f0_0\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.19.1-py36hfa32c7d_0\n",
            "  pytorch            pytorch/linux-64::pytorch-1.6.0-py3.6_cuda10.1.243_cudnn7.6.3_0\n",
            "  six                pkgs/main/noarch::six-1.15.0-py_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\rmkl-service-2.3.0    | 219 KB    |            |   0% \rmkl-service-2.3.0    | 219 KB    | ########## | 100% \rmkl-service-2.3.0    | 219 KB    | ########## | 100% \n",
            "\rblas-1.0             | 6 KB      |            |   0% \rblas-1.0             | 6 KB      | ########## | 100% \n",
            "\rintel-openmp-2020.2  | 786 KB    |            |   0% \rintel-openmp-2020.2  | 786 KB    | ########7  |  88% \rintel-openmp-2020.2  | 786 KB    | ########## | 100% \n",
            "\rnumpy-base-1.19.1    | 4.1 MB    |            |   0% \rnumpy-base-1.19.1    | 4.1 MB    | #####2     |  53% \rnumpy-base-1.19.1    | 4.1 MB    | ########## | 100% \rnumpy-base-1.19.1    | 4.1 MB    | ########## | 100% \n",
            "\rcudatoolkit-10.1.243 | 347.4 MB  |            |   0% \rcudatoolkit-10.1.243 | 347.4 MB  | 2          |   3% \rcudatoolkit-10.1.243 | 347.4 MB  | 6          |   7% \rcudatoolkit-10.1.243 | 347.4 MB  | #          |  11% \rcudatoolkit-10.1.243 | 347.4 MB  | #4         |  15% \rcudatoolkit-10.1.243 | 347.4 MB  | #7         |  17% \rcudatoolkit-10.1.243 | 347.4 MB  | ##         |  20% \rcudatoolkit-10.1.243 | 347.4 MB  | ##3        |  24% \rcudatoolkit-10.1.243 | 347.4 MB  | ##7        |  27% \rcudatoolkit-10.1.243 | 347.4 MB  | ###1       |  31% \rcudatoolkit-10.1.243 | 347.4 MB  | ###4       |  35% \rcudatoolkit-10.1.243 | 347.4 MB  | ###8       |  38% \rcudatoolkit-10.1.243 | 347.4 MB  | ####2      |  43% \rcudatoolkit-10.1.243 | 347.4 MB  | ####6      |  47% \rcudatoolkit-10.1.243 | 347.4 MB  | #####1     |  51% \rcudatoolkit-10.1.243 | 347.4 MB  | #####4     |  55% \rcudatoolkit-10.1.243 | 347.4 MB  | #####8     |  58% \rcudatoolkit-10.1.243 | 347.4 MB  | ######1    |  62% \rcudatoolkit-10.1.243 | 347.4 MB  | ######5    |  65% \rcudatoolkit-10.1.243 | 347.4 MB  | ######9    |  69% \rcudatoolkit-10.1.243 | 347.4 MB  | #######2   |  73% \rcudatoolkit-10.1.243 | 347.4 MB  | #######6   |  77% \rcudatoolkit-10.1.243 | 347.4 MB  | ########   |  81% \rcudatoolkit-10.1.243 | 347.4 MB  | ########4  |  85% \rcudatoolkit-10.1.243 | 347.4 MB  | ########8  |  88% \rcudatoolkit-10.1.243 | 347.4 MB  | #########2 |  92% \rcudatoolkit-10.1.243 | 347.4 MB  | #########6 |  96% \rcudatoolkit-10.1.243 | 347.4 MB  | ########## | 100% \n",
            "\rninja-1.10.1         | 1.4 MB    |            |   0% \rninja-1.10.1         | 1.4 MB    | ########## | 100% \rninja-1.10.1         | 1.4 MB    | ########## | 100% \n",
            "\rnumpy-1.19.1         | 21 KB     |            |   0% \rnumpy-1.19.1         | 21 KB     | ########## | 100% \n",
            "\rpytorch-1.6.0        | 516.3 MB  |            |   0% \rpytorch-1.6.0        | 516.3 MB  |            |   0% \rpytorch-1.6.0        | 516.3 MB  |            |   0% \rpytorch-1.6.0        | 516.3 MB  |            |   0% \rpytorch-1.6.0        | 516.3 MB  |            |   0% \rpytorch-1.6.0        | 516.3 MB  |            |   1% \rpytorch-1.6.0        | 516.3 MB  | 1          |   2% \rpytorch-1.6.0        | 516.3 MB  | 2          |   3% \rpytorch-1.6.0        | 516.3 MB  | 4          |   4% \rpytorch-1.6.0        | 516.3 MB  | 5          |   5% \rpytorch-1.6.0        | 516.3 MB  | 6          |   6% \rpytorch-1.6.0        | 516.3 MB  | 7          |   8% \rpytorch-1.6.0        | 516.3 MB  | 8          |   9% \rpytorch-1.6.0        | 516.3 MB  | 9          |  10% \rpytorch-1.6.0        | 516.3 MB  | #          |  11% \rpytorch-1.6.0        | 516.3 MB  | #2         |  12% \rpytorch-1.6.0        | 516.3 MB  | #3         |  13% \rpytorch-1.6.0        | 516.3 MB  | #4         |  14% \rpytorch-1.6.0        | 516.3 MB  | #5         |  16% \rpytorch-1.6.0        | 516.3 MB  | #6         |  17% \rpytorch-1.6.0        | 516.3 MB  | #7         |  18% \rpytorch-1.6.0        | 516.3 MB  | #8         |  19% \rpytorch-1.6.0        | 516.3 MB  | ##         |  20% \rpytorch-1.6.0        | 516.3 MB  | ##1        |  21% \rpytorch-1.6.0        | 516.3 MB  | ##2        |  22% \rpytorch-1.6.0        | 516.3 MB  | ##3        |  23% \rpytorch-1.6.0        | 516.3 MB  | ##4        |  24% \rpytorch-1.6.0        | 516.3 MB  | ##4        |  25% \rpytorch-1.6.0        | 516.3 MB  | ##5        |  26% \rpytorch-1.6.0        | 516.3 MB  | ##6        |  27% \rpytorch-1.6.0        | 516.3 MB  | ##7        |  28% \rpytorch-1.6.0        | 516.3 MB  | ##8        |  29% \rpytorch-1.6.0        | 516.3 MB  | ##9        |  30% \rpytorch-1.6.0        | 516.3 MB  | ###        |  30% \rpytorch-1.6.0        | 516.3 MB  | ###1       |  31% \rpytorch-1.6.0        | 516.3 MB  | ###2       |  32% \rpytorch-1.6.0        | 516.3 MB  | ###3       |  33% \rpytorch-1.6.0        | 516.3 MB  | ###4       |  34% \rpytorch-1.6.0        | 516.3 MB  | ###5       |  35% \rpytorch-1.6.0        | 516.3 MB  | ###6       |  36% \rpytorch-1.6.0        | 516.3 MB  | ###7       |  37% \rpytorch-1.6.0        | 516.3 MB  | ###8       |  38% \rpytorch-1.6.0        | 516.3 MB  | ###9       |  39% \rpytorch-1.6.0        | 516.3 MB  | ####       |  40% \rpytorch-1.6.0        | 516.3 MB  | ####       |  41% \rpytorch-1.6.0        | 516.3 MB  | ####1      |  42% \rpytorch-1.6.0        | 516.3 MB  | ####2      |  43% \rpytorch-1.6.0        | 516.3 MB  | ####3      |  44% \rpytorch-1.6.0        | 516.3 MB  | ####4      |  44% \rpytorch-1.6.0        | 516.3 MB  | ####5      |  45% \rpytorch-1.6.0        | 516.3 MB  | ####6      |  46% \rpytorch-1.6.0        | 516.3 MB  | ####7      |  47% \rpytorch-1.6.0        | 516.3 MB  | ####8      |  48% \rpytorch-1.6.0        | 516.3 MB  | ####9      |  49% \rpytorch-1.6.0        | 516.3 MB  | #####      |  51% \rpytorch-1.6.0        | 516.3 MB  | #####1     |  52% \rpytorch-1.6.0        | 516.3 MB  | #####2     |  53% \rpytorch-1.6.0        | 516.3 MB  | #####3     |  54% \rpytorch-1.6.0        | 516.3 MB  | #####5     |  55% \rpytorch-1.6.0        | 516.3 MB  | #####6     |  56% \rpytorch-1.6.0        | 516.3 MB  | #####7     |  57% \rpytorch-1.6.0        | 516.3 MB  | #####8     |  59% \rpytorch-1.6.0        | 516.3 MB  | #####9     |  60% \rpytorch-1.6.0        | 516.3 MB  | ######     |  61% \rpytorch-1.6.0        | 516.3 MB  | ######1    |  62% \rpytorch-1.6.0        | 516.3 MB  | ######3    |  63% \rpytorch-1.6.0        | 516.3 MB  | ######4    |  64% \rpytorch-1.6.0        | 516.3 MB  | ######5    |  65% \rpytorch-1.6.0        | 516.3 MB  | ######6    |  66% \rpytorch-1.6.0        | 516.3 MB  | ######7    |  67% \rpytorch-1.6.0        | 516.3 MB  | ######8    |  68% \rpytorch-1.6.0        | 516.3 MB  | ######9    |  69% \rpytorch-1.6.0        | 516.3 MB  | #######    |  71% \rpytorch-1.6.0        | 516.3 MB  | #######1   |  72% \rpytorch-1.6.0        | 516.3 MB  | #######2   |  73% \rpytorch-1.6.0        | 516.3 MB  | #######3   |  74% \rpytorch-1.6.0        | 516.3 MB  | #######5   |  75% \rpytorch-1.6.0        | 516.3 MB  | #######6   |  76% \rpytorch-1.6.0        | 516.3 MB  | #######7   |  77% \rpytorch-1.6.0        | 516.3 MB  | #######8   |  79% \rpytorch-1.6.0        | 516.3 MB  | #######9   |  80% \rpytorch-1.6.0        | 516.3 MB  | ########   |  81% \rpytorch-1.6.0        | 516.3 MB  | ########1  |  82% \rpytorch-1.6.0        | 516.3 MB  | ########3  |  83% \rpytorch-1.6.0        | 516.3 MB  | ########4  |  84% \rpytorch-1.6.0        | 516.3 MB  | ########5  |  85% \rpytorch-1.6.0        | 516.3 MB  | ########6  |  86% \rpytorch-1.6.0        | 516.3 MB  | ########7  |  87% \rpytorch-1.6.0        | 516.3 MB  | ########7  |  88% \rpytorch-1.6.0        | 516.3 MB  | ########8  |  89% \rpytorch-1.6.0        | 516.3 MB  | ########9  |  90% \rpytorch-1.6.0        | 516.3 MB  | #########  |  91% \rpytorch-1.6.0        | 516.3 MB  | #########1 |  92% \rpytorch-1.6.0        | 516.3 MB  | #########2 |  93% \rpytorch-1.6.0        | 516.3 MB  | #########3 |  93% \rpytorch-1.6.0        | 516.3 MB  | #########4 |  95% \rpytorch-1.6.0        | 516.3 MB  | #########5 |  95% \rpytorch-1.6.0        | 516.3 MB  | #########6 |  96% \rpytorch-1.6.0        | 516.3 MB  | #########7 |  97% \rpytorch-1.6.0        | 516.3 MB  | #########8 |  98% \rpytorch-1.6.0        | 516.3 MB  | #########9 |  99% \rpytorch-1.6.0        | 516.3 MB  | ########## | 100% \n",
            "\rmkl_random-1.1.1     | 327 KB    |            |   0% \rmkl_random-1.1.1     | 327 KB    | ########## | 100% \n",
            "\rmkl_fft-1.1.0        | 144 KB    |            |   0% \rmkl_fft-1.1.0        | 144 KB    | ########## | 100% \n",
            "\rsix-1.15.0           | 13 KB     |            |   0% \rsix-1.15.0           | 13 KB     | ########## | 100% \n",
            "\rmkl-2020.2           | 138.3 MB  |            |   0% \rmkl-2020.2           | 138.3 MB  | 4          |   5% \rmkl-2020.2           | 138.3 MB  | #1         |  11% \rmkl-2020.2           | 138.3 MB  | ##         |  20% \rmkl-2020.2           | 138.3 MB  | ###        |  30% \rmkl-2020.2           | 138.3 MB  | ###9       |  39% \rmkl-2020.2           | 138.3 MB  | ####8      |  49% \rmkl-2020.2           | 138.3 MB  | #####7     |  58% \rmkl-2020.2           | 138.3 MB  | ######7    |  67% \rmkl-2020.2           | 138.3 MB  | #######6   |  76% \rmkl-2020.2           | 138.3 MB  | ########5  |  86% \rmkl-2020.2           | 138.3 MB  | #########6 |  96% \rmkl-2020.2           | 138.3 MB  | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7L3e42HW6W4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "08df3156-07fa-4d60-9bf2-6deed6611a27"
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/\"\n",
        "!git clone https://github.com/NVIDIA/apex "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/unilm/layoutlm\n",
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 7431, done.\u001b[K\n",
            "remote: Total 7431 (delta 0), reused 0 (delta 0), pack-reused 7431\u001b[K\n",
            "Receiving objects: 100% (7431/7431), 13.90 MiB | 10.53 MiB/s, done.\n",
            "Resolving deltas: 100% (5024/5024), done.\n",
            "Checking out files: 100% (290/290), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rdw_G_bvN4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ffc6d70d-154a-4521-c51e-2c08a7d45f77"
      },
      "source": [
        "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8 MB 15 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 15.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/site-packages (from torch==1.5.0+cu101) (0.18.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torch==1.5.0+cu101) (1.19.1)\n",
            "Collecting pillow>=4.1.1\n",
            "  Downloading Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 3.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "Successfully installed pillow-7.2.0 torch-1.5.0+cu101 torchvision-0.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woV4btxGW-6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f645b5f7-2b48-4218-cc21-e2ae5966c1b0"
      },
      "source": [
        "\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/apex\"\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/apex\n",
            "/usr/local/lib/python3.6/site-packages/pip/_internal/commands/install.py:236: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Using pip 20.2.2 from /usr/local/lib/python3.6/site-packages/pip (python 3.6)\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-ycdqzm0f\n",
            "Created temporary directory: /tmp/pip-req-tracker-e_az676d\n",
            "Initialized build tracking at /tmp/pip-req-tracker-e_az676d\n",
            "Created build tracker: /tmp/pip-req-tracker-e_az676d\n",
            "Entered build tracker: /tmp/pip-req-tracker-e_az676d\n",
            "Created temporary directory: /tmp/pip-install-vqh62uye\n",
            "Processing /content/drive/My Drive/Colab Notebooks/unilm/layoutlm/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-9ejfhwai\n",
            "  Added file:///content/drive/My%20Drive/Colab%20Notebooks/unilm/layoutlm/apex to build tracker '/tmp/pip-req-tracker-e_az676d'\n",
            "    Running setup.py (path:/tmp/pip-req-build-9ejfhwai/setup.py) egg_info for package from file:///content/drive/My%20Drive/Colab%20Notebooks/unilm/layoutlm/apex\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-8vp0v8cm\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.5.0+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-8vp0v8cm/apex.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-8vp0v8cm/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-8vp0v8cm/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-8vp0v8cm/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-8vp0v8cm/apex.egg-info/SOURCES.txt'\n",
            "    reading manifest file '/tmp/pip-pip-egg-info-8vp0v8cm/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-8vp0v8cm/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-9ejfhwai/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-9ejfhwai has version 0.1, which satisfies requirement apex==0.1 from file:///content/drive/My%20Drive/Colab%20Notebooks/unilm/layoutlm/apex\n",
            "  Removed apex==0.1 from file:///content/drive/My%20Drive/Colab%20Notebooks/unilm/layoutlm/apex from build tracker '/tmp/pip-req-tracker-e_az676d'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-ccqie7r6\n",
            "    Running command /usr/local/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-9ejfhwai/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-9ejfhwai/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-ccqie7r6/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.6m/apex\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.5.0+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-9ejfhwai/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.6/site-packages/torch/utils/cpp_extension.py:304: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
            "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/macros/Macros.h:141:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:262:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                     \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/c10/util/Exception.h:273:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    gcc -pthread -B /usr/local/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                             \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:129:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                             \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:131:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:46:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Tensor.h:11:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/core/TensorBody.h:262:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/site-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/site-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/site-packages/torch/include -I/usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/site-packages/torch/include/TH -I/usr/local/lib/python3.6/site-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/local/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/autograd/profiler.h(100): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/site-packages/torch/include/torch/csrc/autograd/profiler.h(115): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    g++ -pthread -shared -B /usr/local/compiler_compat -L/usr/local/lib -Wl,-rpath=/usr/local/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/site-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/site-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/site-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/site-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/site-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/site-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/site-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/site-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/site-packages/apex\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/site-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/site-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/site-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/site-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/site-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/site-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/site-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/site-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/site-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/site-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/site-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/site-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/site-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/site-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/site-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/site-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/site-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/site-packages\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/site-packages\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/site-packages\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/site-packages\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/site-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    reading manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/site-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-ccqie7r6/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed apex-0.1\n",
            "Removed build tracker: '/tmp/pip-req-tracker-e_az676d'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkNescA_OLNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b8d1b60b-0fb6-47fd-d692-1b3ac98e1ff4"
      },
      "source": [
        "\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/apex\"\n",
        "!pip install ."
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/apex\n",
            "Processing /content/drive/My Drive/Colab Notebooks/unilm/layoutlm/apex\n",
            "Building wheels for collected packages: apex\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-py3-none-any.whl size=192846 sha256=353dd49d78b2023841f51acbed389912d1a52be72d09f266e326bab2eea53dec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n05w2um5/wheels/5e/84/4d/ba6c36aff1f9b8f8ab3ce6be034248e01e816ec599711b7dfd\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "  Attempting uninstall: apex\n",
            "    Found existing installation: apex 0.1\n",
            "    Uninstalling apex-0.1:\n",
            "      Successfully uninstalled apex-0.1\n",
            "Successfully installed apex-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYkLQVKVrDqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb9df4a4-fb12-45e3-9ae5-68eb67343b22"
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/examples/seq_labeling\""
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/examples/seq_labeling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDsI4qxMsmdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec0e5ed5-ae7f-4d5e-bf15-dba6226a3bfa"
      },
      "source": [
        "!sh preprocess.sh"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-10 00:00:39--  https://guillaumejaume.github.io/FUNSD/dataset.zip\n",
            "Resolving guillaumejaume.github.io (guillaumejaume.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to guillaumejaume.github.io (guillaumejaume.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16838830 (16M) [application/zip]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip         100%[===================>]  16.06M  35.4MB/s    in 0.5s    \n",
            "\n",
            "2020-09-10 00:00:39 (35.4 MB/s) - ‘dataset.zip’ saved [16838830/16838830]\n",
            "\n",
            "Archive:  dataset.zip\n",
            "   creating: dataset/\n",
            "   creating: dataset/training_data/\n",
            "  inflating: dataset/training_data/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/dataset/\n",
            "   creating: __MACOSX/dataset/training_data/\n",
            "  inflating: __MACOSX/dataset/training_data/._.DS_Store  \n",
            "   creating: dataset/training_data/images/\n",
            "  inflating: dataset/training_data/images/92091873.png  \n",
            "   creating: __MACOSX/dataset/training_data/images/\n",
            "  inflating: __MACOSX/dataset/training_data/images/._92091873.png  \n",
            "  inflating: dataset/training_data/images/91939637.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91939637.png  \n",
            "  inflating: dataset/training_data/images/87533049.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._87533049.png  \n",
            "  inflating: dataset/training_data/images/01073843.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._01073843.png  \n",
            "  inflating: dataset/training_data/images/92586242.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92586242.png  \n",
            "  inflating: dataset/training_data/images/0012529284.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0012529284.png  \n",
            "  inflating: dataset/training_data/images/71341634.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71341634.png  \n",
            "  inflating: dataset/training_data/images/0001477983.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001477983.png  \n",
            "  inflating: dataset/training_data/images/91315069_91315070.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91315069_91315070.png  \n",
            "  inflating: dataset/training_data/images/0060207528.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060207528.png  \n",
            "  inflating: dataset/training_data/images/91161344_91161347.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91161344_91161347.png  \n",
            "  inflating: dataset/training_data/images/71366499.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71366499.png  \n",
            "  inflating: dataset/training_data/images/00922237.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00922237.png  \n",
            "  inflating: dataset/training_data/images/91355841.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91355841.png  \n",
            "  inflating: dataset/training_data/images/93380187.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._93380187.png  \n",
            "  inflating: dataset/training_data/images/01150773_01150774.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._01150773_01150774.png  \n",
            "  inflating: dataset/training_data/images/0060165115.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060165115.png  \n",
            "  inflating: dataset/training_data/images/91914407.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91914407.png  \n",
            "  inflating: dataset/training_data/images/92081358_1359.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92081358_1359.png  \n",
            "  inflating: dataset/training_data/images/660978.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._660978.png  \n",
            "  inflating: dataset/training_data/images/0011974919.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011974919.png  \n",
            "  inflating: dataset/training_data/images/81749056_9057.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._81749056_9057.png  \n",
            "  inflating: dataset/training_data/images/00093726.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00093726.png  \n",
            "  inflating: dataset/training_data/images/0000999294.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0000999294.png  \n",
            "  inflating: dataset/training_data/images/81186212.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._81186212.png  \n",
            "  inflating: dataset/training_data/images/0060077689.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060077689.png  \n",
            "  inflating: dataset/training_data/images/87672097.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._87672097.png  \n",
            "  inflating: dataset/training_data/images/11875011.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._11875011.png  \n",
            "  inflating: dataset/training_data/images/00851772_1780.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00851772_1780.png  \n",
            "  inflating: dataset/training_data/images/0011859695.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011859695.png  \n",
            "  inflating: dataset/training_data/images/81619511_9513.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._81619511_9513.png  \n",
            "  inflating: dataset/training_data/images/0001456787.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001456787.png  \n",
            "  inflating: dataset/training_data/images/81310636.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._81310636.png  \n",
            "  inflating: dataset/training_data/images/0060080406.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060080406.png  \n",
            "  inflating: dataset/training_data/images/0011973451.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011973451.png  \n",
            "  inflating: dataset/training_data/images/91104867.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91104867.png  \n",
            "  inflating: dataset/training_data/images/00836244.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00836244.png  \n",
            "  inflating: dataset/training_data/images/0001476912.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001476912.png  \n",
            "  inflating: dataset/training_data/images/12052385.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._12052385.png  \n",
            "  inflating: dataset/training_data/images/0060255888.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060255888.png  \n",
            "  inflating: dataset/training_data/images/71206427.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71206427.png  \n",
            "  inflating: dataset/training_data/images/0012199830.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0012199830.png  \n",
            "  inflating: dataset/training_data/images/0001463448.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001463448.png  \n",
            "  inflating: dataset/training_data/images/0000990274.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0000990274.png  \n",
            "  inflating: dataset/training_data/images/716552.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._716552.png  \n",
            "  inflating: dataset/training_data/images/00920222.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00920222.png  \n",
            "  inflating: dataset/training_data/images/0012529295.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0012529295.png  \n",
            "  inflating: dataset/training_data/images/80728670.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._80728670.png  \n",
            "  inflating: dataset/training_data/images/93213298.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._93213298.png  \n",
            "  inflating: dataset/training_data/images/71108371.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71108371.png  \n",
            "  inflating: dataset/training_data/images/0001209043.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001209043.png  \n",
            "  inflating: dataset/training_data/images/88057519.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._88057519.png  \n",
            "  inflating: dataset/training_data/images/01191071_1072.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._01191071_1072.png  \n",
            "  inflating: dataset/training_data/images/00836816.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00836816.png  \n",
            "  inflating: dataset/training_data/images/91361993.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91361993.png  \n",
            "  inflating: dataset/training_data/images/92298125.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92298125.png  \n",
            "  inflating: dataset/training_data/images/00040534.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00040534.png  \n",
            "  inflating: dataset/training_data/images/0011838621.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011838621.png  \n",
            "  inflating: dataset/training_data/images/0060029036.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060029036.png  \n",
            "  inflating: dataset/training_data/images/0000989556.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0000989556.png  \n",
            "  inflating: dataset/training_data/images/0060024314.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060024314.png  \n",
            "  inflating: dataset/training_data/images/0001129658.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001129658.png  \n",
            "  inflating: dataset/training_data/images/0071032790.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0071032790.png  \n",
            "  inflating: dataset/training_data/images/00838511_00838525.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00838511_00838525.png  \n",
            "  inflating: dataset/training_data/images/87682908.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._87682908.png  \n",
            "  inflating: dataset/training_data/images/0060214859.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060214859.png  \n",
            "  inflating: dataset/training_data/images/00070353.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00070353.png  \n",
            "  inflating: dataset/training_data/images/93351929_93351931.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._93351929_93351931.png  \n",
            "  inflating: dataset/training_data/images/0001438955.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001438955.png  \n",
            "  inflating: dataset/training_data/images/81619486_9488.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._81619486_9488.png  \n",
            "  inflating: dataset/training_data/images/00920294.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00920294.png  \n",
            "  inflating: dataset/training_data/images/0000971160.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0000971160.png  \n",
            "  inflating: dataset/training_data/images/0012947358.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0012947358.png  \n",
            "  inflating: dataset/training_data/images/00865872.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00865872.png  \n",
            "  inflating: dataset/training_data/images/91391286.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91391286.png  \n",
            "  inflating: dataset/training_data/images/01122115.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._01122115.png  \n",
            "  inflating: dataset/training_data/images/01408099_01408101.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._01408099_01408101.png  \n",
            "  inflating: dataset/training_data/images/80310840a.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._80310840a.png  \n",
            "  inflating: dataset/training_data/images/0012602424.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0012602424.png  \n",
            "  inflating: dataset/training_data/images/0071032807.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0071032807.png  \n",
            "  inflating: dataset/training_data/images/0060308251.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060308251.png  \n",
            "  inflating: dataset/training_data/images/92094746.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92094746.png  \n",
            "  inflating: dataset/training_data/images/0060302201.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060302201.png  \n",
            "  inflating: dataset/training_data/images/0060094595.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060094595.png  \n",
            "  inflating: dataset/training_data/images/71190280.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71190280.png  \n",
            "  inflating: dataset/training_data/images/92433599_92433601.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92433599_92433601.png  \n",
            "  inflating: dataset/training_data/images/0060091229.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060091229.png  \n",
            "  inflating: dataset/training_data/images/89386032.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._89386032.png  \n",
            "  inflating: dataset/training_data/images/91974562.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91974562.png  \n",
            "  inflating: dataset/training_data/images/92094751.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92094751.png  \n",
            "  inflating: dataset/training_data/images/89817999_8002.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._89817999_8002.png  \n",
            "  inflating: dataset/training_data/images/71601299.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71601299.png  \n",
            "  inflating: dataset/training_data/images/00851879.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00851879.png  \n",
            "  inflating: dataset/training_data/images/92039708_9710.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92039708_9710.png  \n",
            "  inflating: dataset/training_data/images/92657391.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92657391.png  \n",
            "  inflating: dataset/training_data/images/80718412_8413.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._80718412_8413.png  \n",
            "  inflating: dataset/training_data/images/00860012_00860014.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00860012_00860014.png  \n",
            "  inflating: dataset/training_data/images/93329540.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._93329540.png  \n",
            "  inflating: dataset/training_data/images/0060068489.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060068489.png  \n",
            "  inflating: dataset/training_data/images/12603270.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._12603270.png  \n",
            "  inflating: dataset/training_data/images/0060308461.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060308461.png  \n",
            "  inflating: dataset/training_data/images/0060270727.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060270727.png  \n",
            "  inflating: dataset/training_data/images/00837285.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00837285.png  \n",
            "  inflating: dataset/training_data/images/91356315.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91356315.png  \n",
            "  inflating: dataset/training_data/images/0011899960.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011899960.png  \n",
            "  inflating: dataset/training_data/images/82254638.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._82254638.png  \n",
            "  inflating: dataset/training_data/images/0001118259.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001118259.png  \n",
            "  inflating: dataset/training_data/images/0011906503.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011906503.png  \n",
            "  inflating: dataset/training_data/images/91391310.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91391310.png  \n",
            "  inflating: dataset/training_data/images/01197604.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._01197604.png  \n",
            "  inflating: dataset/training_data/images/80707440_7443.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._80707440_7443.png  \n",
            "  inflating: dataset/training_data/images/11508234.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._11508234.png  \n",
            "  inflating: dataset/training_data/images/0011845203.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011845203.png  \n",
            "  inflating: dataset/training_data/images/0060262650.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060262650.png  \n",
            "  inflating: dataset/training_data/images/0060173256.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060173256.png  \n",
            "  inflating: dataset/training_data/images/88547278_88547279.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._88547278_88547279.png  \n",
            "  inflating: dataset/training_data/images/0001123541.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001123541.png  \n",
            "  inflating: dataset/training_data/images/81574683.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._81574683.png  \n",
            "  inflating: dataset/training_data/images/0001239897.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001239897.png  \n",
            "  inflating: dataset/training_data/images/0011856542.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011856542.png  \n",
            "  inflating: dataset/training_data/images/0060025670.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060025670.png  \n",
            "  inflating: dataset/training_data/images/89867723.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._89867723.png  \n",
            "  inflating: dataset/training_data/images/0012178355.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0012178355.png  \n",
            "  inflating: dataset/training_data/images/91856041_6049.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91856041_6049.png  \n",
            "  inflating: dataset/training_data/images/93455715.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._93455715.png  \n",
            "  inflating: dataset/training_data/images/0011976929.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011976929.png  \n",
            "  inflating: dataset/training_data/images/0060007216.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060007216.png  \n",
            "  inflating: dataset/training_data/images/0001485288.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001485288.png  \n",
            "  inflating: dataset/training_data/images/0001463282.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0001463282.png  \n",
            "  inflating: dataset/training_data/images/0030041455.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0030041455.png  \n",
            "  inflating: dataset/training_data/images/71202511.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71202511.png  \n",
            "  inflating: dataset/training_data/images/92327794.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92327794.png  \n",
            "  inflating: dataset/training_data/images/0060136394.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060136394.png  \n",
            "  inflating: dataset/training_data/images/89368010.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._89368010.png  \n",
            "  inflating: dataset/training_data/images/92314414.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92314414.png  \n",
            "  inflating: dataset/training_data/images/92657311_7313.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._92657311_7313.png  \n",
            "  inflating: dataset/training_data/images/13149651.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._13149651.png  \n",
            "  inflating: dataset/training_data/images/91903177.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91903177.png  \n",
            "  inflating: dataset/training_data/images/71563825.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._71563825.png  \n",
            "  inflating: dataset/training_data/images/00283813.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00283813.png  \n",
            "  inflating: dataset/training_data/images/00866042.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._00866042.png  \n",
            "  inflating: dataset/training_data/images/0060036622.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060036622.png  \n",
            "  inflating: dataset/training_data/images/0011505151.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0011505151.png  \n",
            "  inflating: dataset/training_data/images/0013255595.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0013255595.png  \n",
            "  inflating: dataset/training_data/images/0030031163.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0030031163.png  \n",
            "  inflating: dataset/training_data/images/91581919.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91581919.png  \n",
            "  inflating: dataset/training_data/images/91372360.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._91372360.png  \n",
            "  inflating: dataset/training_data/images/12825369.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._12825369.png  \n",
            "  inflating: dataset/training_data/images/0060000813.png  \n",
            "  inflating: __MACOSX/dataset/training_data/images/._0060000813.png  \n",
            "  inflating: __MACOSX/dataset/training_data/._images  \n",
            "   creating: dataset/training_data/annotations/\n",
            "  inflating: dataset/training_data/annotations/71206427.json  \n",
            "   creating: __MACOSX/dataset/training_data/annotations/\n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71206427.json  \n",
            "  inflating: dataset/training_data/annotations/0001123541.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001123541.json  \n",
            "  inflating: dataset/training_data/annotations/92039708_9710.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92039708_9710.json  \n",
            "  inflating: dataset/training_data/annotations/0060029036.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060029036.json  \n",
            "  inflating: dataset/training_data/annotations/81619511_9513.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._81619511_9513.json  \n",
            "  inflating: dataset/training_data/annotations/89386032.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._89386032.json  \n",
            "  inflating: dataset/training_data/annotations/0001209043.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001209043.json  \n",
            "  inflating: dataset/training_data/annotations/0060262650.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060262650.json  \n",
            "  inflating: dataset/training_data/annotations/0001129658.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001129658.json  \n",
            "  inflating: dataset/training_data/annotations/0060165115.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060165115.json  \n",
            "  inflating: dataset/training_data/annotations/0060007216.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060007216.json  \n",
            "  inflating: dataset/training_data/annotations/00093726.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00093726.json  \n",
            "  inflating: dataset/training_data/annotations/00836244.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00836244.json  \n",
            "  inflating: dataset/training_data/annotations/0060094595.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060094595.json  \n",
            "  inflating: dataset/training_data/annotations/80728670.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._80728670.json  \n",
            "  inflating: dataset/training_data/annotations/92327794.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92327794.json  \n",
            "  inflating: dataset/training_data/annotations/00922237.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00922237.json  \n",
            "  inflating: dataset/training_data/annotations/92298125.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92298125.json  \n",
            "  inflating: dataset/training_data/annotations/12825369.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._12825369.json  \n",
            "  inflating: dataset/training_data/annotations/92586242.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92586242.json  \n",
            "  inflating: dataset/training_data/annotations/0001463448.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001463448.json  \n",
            "  inflating: dataset/training_data/annotations/0060302201.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060302201.json  \n",
            "  inflating: dataset/training_data/annotations/91391286.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91391286.json  \n",
            "  inflating: dataset/training_data/annotations/0060308461.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060308461.json  \n",
            "  inflating: dataset/training_data/annotations/81619486_9488.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._81619486_9488.json  \n",
            "  inflating: dataset/training_data/annotations/0071032790.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0071032790.json  \n",
            "  inflating: dataset/training_data/annotations/0060080406.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060080406.json  \n",
            "  inflating: dataset/training_data/annotations/0012529284.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0012529284.json  \n",
            "  inflating: dataset/training_data/annotations/0060036622.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060036622.json  \n",
            "  inflating: dataset/training_data/annotations/71190280.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71190280.json  \n",
            "  inflating: dataset/training_data/annotations/93455715.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._93455715.json  \n",
            "  inflating: dataset/training_data/annotations/87682908.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._87682908.json  \n",
            "  inflating: dataset/training_data/annotations/91356315.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91356315.json  \n",
            "  inflating: dataset/training_data/annotations/87533049.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._87533049.json  \n",
            "  inflating: dataset/training_data/annotations/0060308251.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060308251.json  \n",
            "  inflating: dataset/training_data/annotations/01122115.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._01122115.json  \n",
            "  inflating: dataset/training_data/annotations/71601299.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71601299.json  \n",
            "  inflating: dataset/training_data/annotations/93329540.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._93329540.json  \n",
            "  inflating: dataset/training_data/annotations/0000990274.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0000990274.json  \n",
            "  inflating: dataset/training_data/annotations/71563825.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71563825.json  \n",
            "  inflating: dataset/training_data/annotations/0060255888.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060255888.json  \n",
            "  inflating: dataset/training_data/annotations/0000989556.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0000989556.json  \n",
            "  inflating: dataset/training_data/annotations/0011505151.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011505151.json  \n",
            "  inflating: dataset/training_data/annotations/00070353.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00070353.json  \n",
            "  inflating: dataset/training_data/annotations/0012529295.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0012529295.json  \n",
            "  inflating: dataset/training_data/annotations/81574683.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._81574683.json  \n",
            "  inflating: dataset/training_data/annotations/0060136394.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060136394.json  \n",
            "  inflating: dataset/training_data/annotations/0030031163.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0030031163.json  \n",
            "  inflating: dataset/training_data/annotations/81749056_9057.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._81749056_9057.json  \n",
            "  inflating: dataset/training_data/annotations/660978.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._660978.json  \n",
            "  inflating: dataset/training_data/annotations/0060214859.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060214859.json  \n",
            "  inflating: dataset/training_data/annotations/92091873.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92091873.json  \n",
            "  inflating: dataset/training_data/annotations/71202511.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71202511.json  \n",
            "  inflating: dataset/training_data/annotations/92657391.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92657391.json  \n",
            "  inflating: dataset/training_data/annotations/11508234.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._11508234.json  \n",
            "  inflating: dataset/training_data/annotations/0011973451.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011973451.json  \n",
            "  inflating: dataset/training_data/annotations/91355841.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91355841.json  \n",
            "  inflating: dataset/training_data/annotations/0001476912.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001476912.json  \n",
            "  inflating: dataset/training_data/annotations/00920294.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00920294.json  \n",
            "  inflating: dataset/training_data/annotations/0001438955.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001438955.json  \n",
            "  inflating: dataset/training_data/annotations/01073843.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._01073843.json  \n",
            "  inflating: dataset/training_data/annotations/0011856542.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011856542.json  \n",
            "  inflating: dataset/training_data/annotations/93213298.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._93213298.json  \n",
            "  inflating: dataset/training_data/annotations/0012178355.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0012178355.json  \n",
            "  inflating: dataset/training_data/annotations/89867723.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._89867723.json  \n",
            "  inflating: dataset/training_data/annotations/92433599_92433601.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92433599_92433601.json  \n",
            "  inflating: dataset/training_data/annotations/87672097.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._87672097.json  \n",
            "  inflating: dataset/training_data/annotations/91315069_91315070.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91315069_91315070.json  \n",
            "  inflating: dataset/training_data/annotations/0060077689.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060077689.json  \n",
            "  inflating: dataset/training_data/annotations/0060000813.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060000813.json  \n",
            "  inflating: dataset/training_data/annotations/92081358_1359.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92081358_1359.json  \n",
            "  inflating: dataset/training_data/annotations/0071032807.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0071032807.json  \n",
            "  inflating: dataset/training_data/annotations/01197604.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._01197604.json  \n",
            "  inflating: dataset/training_data/annotations/71366499.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71366499.json  \n",
            "  inflating: dataset/training_data/annotations/11875011.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._11875011.json  \n",
            "  inflating: dataset/training_data/annotations/91104867.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91104867.json  \n",
            "  inflating: dataset/training_data/annotations/91391310.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91391310.json  \n",
            "  inflating: dataset/training_data/annotations/0011899960.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011899960.json  \n",
            "  inflating: dataset/training_data/annotations/81186212.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._81186212.json  \n",
            "  inflating: dataset/training_data/annotations/82254638.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._82254638.json  \n",
            "  inflating: dataset/training_data/annotations/01150773_01150774.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._01150773_01150774.json  \n",
            "  inflating: dataset/training_data/annotations/00920222.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00920222.json  \n",
            "  inflating: dataset/training_data/annotations/92314414.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92314414.json  \n",
            "  inflating: dataset/training_data/annotations/00838511_00838525.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00838511_00838525.json  \n",
            "  inflating: dataset/training_data/annotations/716552.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._716552.json  \n",
            "  inflating: dataset/training_data/annotations/91372360.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91372360.json  \n",
            "  inflating: dataset/training_data/annotations/71341634.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71341634.json  \n",
            "  inflating: dataset/training_data/annotations/91856041_6049.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91856041_6049.json  \n",
            "  inflating: dataset/training_data/annotations/00040534.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00040534.json  \n",
            "  inflating: dataset/training_data/annotations/89368010.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._89368010.json  \n",
            "  inflating: dataset/training_data/annotations/91914407.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91914407.json  \n",
            "  inflating: dataset/training_data/annotations/0060024314.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060024314.json  \n",
            "  inflating: dataset/training_data/annotations/00866042.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00866042.json  \n",
            "  inflating: dataset/training_data/annotations/12603270.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._12603270.json  \n",
            "  inflating: dataset/training_data/annotations/0012602424.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0012602424.json  \n",
            "  inflating: dataset/training_data/annotations/80718412_8413.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._80718412_8413.json  \n",
            "  inflating: dataset/training_data/annotations/88547278_88547279.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._88547278_88547279.json  \n",
            "  inflating: dataset/training_data/annotations/0000971160.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0000971160.json  \n",
            "  inflating: dataset/training_data/annotations/13149651.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._13149651.json  \n",
            "  inflating: dataset/training_data/annotations/0060091229.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060091229.json  \n",
            "  inflating: dataset/training_data/annotations/91939637.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91939637.json  \n",
            "  inflating: dataset/training_data/annotations/0011859695.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011859695.json  \n",
            "  inflating: dataset/training_data/annotations/00851772_1780.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00851772_1780.json  \n",
            "  inflating: dataset/training_data/annotations/80707440_7443.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._80707440_7443.json  \n",
            "  inflating: dataset/training_data/annotations/0012947358.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0012947358.json  \n",
            "  inflating: dataset/training_data/annotations/88057519.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._88057519.json  \n",
            "  inflating: dataset/training_data/annotations/71108371.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._71108371.json  \n",
            "  inflating: dataset/training_data/annotations/91903177.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91903177.json  \n",
            "  inflating: dataset/training_data/annotations/91581919.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91581919.json  \n",
            "  inflating: dataset/training_data/annotations/0013255595.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0013255595.json  \n",
            "  inflating: dataset/training_data/annotations/92657311_7313.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92657311_7313.json  \n",
            "  inflating: dataset/training_data/annotations/0060173256.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060173256.json  \n",
            "  inflating: dataset/training_data/annotations/0001477983.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001477983.json  \n",
            "  inflating: dataset/training_data/annotations/92094751.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92094751.json  \n",
            "  inflating: dataset/training_data/annotations/0030041455.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0030041455.json  \n",
            "  inflating: dataset/training_data/annotations/93380187.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._93380187.json  \n",
            "  inflating: dataset/training_data/annotations/93351929_93351931.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._93351929_93351931.json  \n",
            "  inflating: dataset/training_data/annotations/01191071_1072.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._01191071_1072.json  \n",
            "  inflating: dataset/training_data/annotations/0011976929.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011976929.json  \n",
            "  inflating: dataset/training_data/annotations/0060207528.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060207528.json  \n",
            "  inflating: dataset/training_data/annotations/0000999294.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0000999294.json  \n",
            "  inflating: dataset/training_data/annotations/00851879.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00851879.json  \n",
            "  inflating: dataset/training_data/annotations/0001485288.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001485288.json  \n",
            "  inflating: dataset/training_data/annotations/0012199830.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0012199830.json  \n",
            "  inflating: dataset/training_data/annotations/00865872.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00865872.json  \n",
            "  inflating: dataset/training_data/annotations/91361993.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91361993.json  \n",
            "  inflating: dataset/training_data/annotations/00283813.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00283813.json  \n",
            "  inflating: dataset/training_data/annotations/0001118259.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001118259.json  \n",
            "  inflating: dataset/training_data/annotations/91974562.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91974562.json  \n",
            "  inflating: dataset/training_data/annotations/0060025670.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060025670.json  \n",
            "  inflating: dataset/training_data/annotations/12052385.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._12052385.json  \n",
            "  inflating: dataset/training_data/annotations/0060068489.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060068489.json  \n",
            "  inflating: dataset/training_data/annotations/0001456787.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001456787.json  \n",
            "  inflating: dataset/training_data/annotations/91161344_91161347.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._91161344_91161347.json  \n",
            "  inflating: dataset/training_data/annotations/0060270727.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0060270727.json  \n",
            "  inflating: dataset/training_data/annotations/01408099_01408101.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._01408099_01408101.json  \n",
            "  inflating: dataset/training_data/annotations/0011974919.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011974919.json  \n",
            "  inflating: dataset/training_data/annotations/00837285.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00837285.json  \n",
            "  inflating: dataset/training_data/annotations/89817999_8002.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._89817999_8002.json  \n",
            "  inflating: dataset/training_data/annotations/00836816.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00836816.json  \n",
            "  inflating: dataset/training_data/annotations/0001239897.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001239897.json  \n",
            "  inflating: dataset/training_data/annotations/81310636.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._81310636.json  \n",
            "  inflating: dataset/training_data/annotations/92094746.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._92094746.json  \n",
            "  inflating: dataset/training_data/annotations/0011838621.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011838621.json  \n",
            "  inflating: dataset/training_data/annotations/00860012_00860014.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._00860012_00860014.json  \n",
            "  inflating: dataset/training_data/annotations/0011845203.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011845203.json  \n",
            "  inflating: dataset/training_data/annotations/0011906503.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0011906503.json  \n",
            "  inflating: dataset/training_data/annotations/0001463282.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._0001463282.json  \n",
            "  inflating: dataset/training_data/annotations/80310840a.json  \n",
            "  inflating: __MACOSX/dataset/training_data/annotations/._80310840a.json  \n",
            "  inflating: __MACOSX/dataset/training_data/._annotations  \n",
            "  inflating: __MACOSX/dataset/._training_data  \n",
            "   creating: dataset/testing_data/\n",
            "  inflating: dataset/testing_data/.DS_Store  \n",
            "   creating: __MACOSX/dataset/testing_data/\n",
            "  inflating: __MACOSX/dataset/testing_data/._.DS_Store  \n",
            "   creating: dataset/testing_data/images/\n",
            "  inflating: dataset/testing_data/images/82837252.png  \n",
            "   creating: __MACOSX/dataset/testing_data/images/\n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82837252.png  \n",
            "  inflating: dataset/testing_data/images/85201976.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._85201976.png  \n",
            "  inflating: dataset/testing_data/images/86263525.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86263525.png  \n",
            "  inflating: dataset/testing_data/images/82251504.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82251504.png  \n",
            "  inflating: dataset/testing_data/images/93106788.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._93106788.png  \n",
            "  inflating: dataset/testing_data/images/82573104.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82573104.png  \n",
            "  inflating: dataset/testing_data/images/87528321.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87528321.png  \n",
            "  inflating: dataset/testing_data/images/85240939.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._85240939.png  \n",
            "  inflating: dataset/testing_data/images/82562350.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82562350.png  \n",
            "  inflating: dataset/testing_data/images/82253245_3247.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82253245_3247.png  \n",
            "  inflating: dataset/testing_data/images/87093315_87093318.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87093315_87093318.png  \n",
            "  inflating: dataset/testing_data/images/83443897.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83443897.png  \n",
            "  inflating: dataset/testing_data/images/87332450.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87332450.png  \n",
            "  inflating: dataset/testing_data/images/89856243.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._89856243.png  \n",
            "  inflating: dataset/testing_data/images/83635935.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83635935.png  \n",
            "  inflating: dataset/testing_data/images/82250337_0338.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82250337_0338.png  \n",
            "  inflating: dataset/testing_data/images/82200067_0069.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82200067_0069.png  \n",
            "  inflating: dataset/testing_data/images/92380595.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._92380595.png  \n",
            "  inflating: dataset/testing_data/images/86236474_6476.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86236474_6476.png  \n",
            "  inflating: dataset/testing_data/images/82491256.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82491256.png  \n",
            "  inflating: dataset/testing_data/images/85540866.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._85540866.png  \n",
            "  inflating: dataset/testing_data/images/86244113.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86244113.png  \n",
            "  inflating: dataset/testing_data/images/83823750.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83823750.png  \n",
            "  inflating: dataset/testing_data/images/83594639.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83594639.png  \n",
            "  inflating: dataset/testing_data/images/87528380.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87528380.png  \n",
            "  inflating: dataset/testing_data/images/86220490.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86220490.png  \n",
            "  inflating: dataset/testing_data/images/87086073.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87086073.png  \n",
            "  inflating: dataset/testing_data/images/87147607.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87147607.png  \n",
            "  inflating: dataset/testing_data/images/82252956_2958.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82252956_2958.png  \n",
            "  inflating: dataset/testing_data/images/83641919_1921.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83641919_1921.png  \n",
            "  inflating: dataset/testing_data/images/82253058_3059.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82253058_3059.png  \n",
            "  inflating: dataset/testing_data/images/87125460.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87125460.png  \n",
            "  inflating: dataset/testing_data/images/83624198.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83624198.png  \n",
            "  inflating: dataset/testing_data/images/82504862.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82504862.png  \n",
            "  inflating: dataset/testing_data/images/86328049_8050.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86328049_8050.png  \n",
            "  inflating: dataset/testing_data/images/82254765.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82254765.png  \n",
            "  inflating: dataset/testing_data/images/86079776_9777.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86079776_9777.png  \n",
            "  inflating: dataset/testing_data/images/83553333_3334.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83553333_3334.png  \n",
            "  inflating: dataset/testing_data/images/83573282.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83573282.png  \n",
            "  inflating: dataset/testing_data/images/87137840.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87137840.png  \n",
            "  inflating: dataset/testing_data/images/87428306.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87428306.png  \n",
            "  inflating: dataset/testing_data/images/86230203_0206.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86230203_0206.png  \n",
            "  inflating: dataset/testing_data/images/87594142_87594144.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._87594142_87594144.png  \n",
            "  inflating: dataset/testing_data/images/91814768_91814769.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._91814768_91814769.png  \n",
            "  inflating: dataset/testing_data/images/86075409_5410.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._86075409_5410.png  \n",
            "  inflating: dataset/testing_data/images/83772145.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83772145.png  \n",
            "  inflating: dataset/testing_data/images/82253362_3364.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82253362_3364.png  \n",
            "  inflating: dataset/testing_data/images/85629964.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._85629964.png  \n",
            "  inflating: dataset/testing_data/images/82092117.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._82092117.png  \n",
            "  inflating: dataset/testing_data/images/83996357.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/images/._83996357.png  \n",
            "  inflating: __MACOSX/dataset/testing_data/._images  \n",
            "   creating: dataset/testing_data/annotations/\n",
            "  inflating: dataset/testing_data/annotations/83594639.json  \n",
            "   creating: __MACOSX/dataset/testing_data/annotations/\n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83594639.json  \n",
            "  inflating: dataset/testing_data/annotations/86236474_6476.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86236474_6476.json  \n",
            "  inflating: dataset/testing_data/annotations/83553333_3334.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83553333_3334.json  \n",
            "  inflating: dataset/testing_data/annotations/82200067_0069.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82200067_0069.json  \n",
            "  inflating: dataset/testing_data/annotations/82504862.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82504862.json  \n",
            "  inflating: dataset/testing_data/annotations/87086073.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87086073.json  \n",
            "  inflating: dataset/testing_data/annotations/89856243.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._89856243.json  \n",
            "  inflating: dataset/testing_data/annotations/85629964.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._85629964.json  \n",
            "  inflating: dataset/testing_data/annotations/83996357.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83996357.json  \n",
            "  inflating: dataset/testing_data/annotations/86079776_9777.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86079776_9777.json  \n",
            "  inflating: dataset/testing_data/annotations/83772145.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83772145.json  \n",
            "  inflating: dataset/testing_data/annotations/82252956_2958.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82252956_2958.json  \n",
            "  inflating: dataset/testing_data/annotations/87528321.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87528321.json  \n",
            "  inflating: dataset/testing_data/annotations/82250337_0338.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82250337_0338.json  \n",
            "  inflating: dataset/testing_data/annotations/83635935.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83635935.json  \n",
            "  inflating: dataset/testing_data/annotations/82254765.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82254765.json  \n",
            "  inflating: dataset/testing_data/annotations/82573104.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82573104.json  \n",
            "  inflating: dataset/testing_data/annotations/82253058_3059.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82253058_3059.json  \n",
            "  inflating: dataset/testing_data/annotations/87428306.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87428306.json  \n",
            "  inflating: dataset/testing_data/annotations/82253362_3364.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82253362_3364.json  \n",
            "  inflating: dataset/testing_data/annotations/87137840.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87137840.json  \n",
            "  inflating: dataset/testing_data/annotations/87147607.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87147607.json  \n",
            "  inflating: dataset/testing_data/annotations/82251504.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82251504.json  \n",
            "  inflating: dataset/testing_data/annotations/83823750.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83823750.json  \n",
            "  inflating: dataset/testing_data/annotations/82253245_3247.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82253245_3247.json  \n",
            "  inflating: dataset/testing_data/annotations/92380595.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._92380595.json  \n",
            "  inflating: dataset/testing_data/annotations/85201976.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._85201976.json  \n",
            "  inflating: dataset/testing_data/annotations/83443897.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83443897.json  \n",
            "  inflating: dataset/testing_data/annotations/85240939.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._85240939.json  \n",
            "  inflating: dataset/testing_data/annotations/87332450.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87332450.json  \n",
            "  inflating: dataset/testing_data/annotations/87528380.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87528380.json  \n",
            "  inflating: dataset/testing_data/annotations/91814768_91814769.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._91814768_91814769.json  \n",
            "  inflating: dataset/testing_data/annotations/82562350.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82562350.json  \n",
            "  inflating: dataset/testing_data/annotations/86244113.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86244113.json  \n",
            "  inflating: dataset/testing_data/annotations/82491256.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82491256.json  \n",
            "  inflating: dataset/testing_data/annotations/86328049_8050.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86328049_8050.json  \n",
            "  inflating: dataset/testing_data/annotations/82837252.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82837252.json  \n",
            "  inflating: dataset/testing_data/annotations/83641919_1921.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83641919_1921.json  \n",
            "  inflating: dataset/testing_data/annotations/83573282.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83573282.json  \n",
            "  inflating: dataset/testing_data/annotations/86220490.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86220490.json  \n",
            "  inflating: dataset/testing_data/annotations/85540866.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._85540866.json  \n",
            "  inflating: dataset/testing_data/annotations/86263525.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86263525.json  \n",
            "  inflating: dataset/testing_data/annotations/82092117.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._82092117.json  \n",
            "  inflating: dataset/testing_data/annotations/93106788.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._93106788.json  \n",
            "  inflating: dataset/testing_data/annotations/86230203_0206.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86230203_0206.json  \n",
            "  inflating: dataset/testing_data/annotations/87594142_87594144.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87594142_87594144.json  \n",
            "  inflating: dataset/testing_data/annotations/87093315_87093318.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87093315_87093318.json  \n",
            "  inflating: dataset/testing_data/annotations/83624198.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._83624198.json  \n",
            "  inflating: dataset/testing_data/annotations/86075409_5410.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._86075409_5410.json  \n",
            "  inflating: dataset/testing_data/annotations/87125460.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/annotations/._87125460.json  \n",
            "  inflating: __MACOSX/dataset/testing_data/._annotations  \n",
            "  inflating: __MACOSX/dataset/._testing_data  \n",
            "  inflating: dataset/.DS_Store       \n",
            "  inflating: __MACOSX/dataset/._.DS_Store  \n",
            "  inflating: __MACOSX/._dataset      \n",
            "Traceback (most recent call last):\n",
            "  File \"preprocess.py\", line 215, in <module>\n",
            "    convert(args)\n",
            "  File \"preprocess.py\", line 58, in convert\n",
            "    image = Image.open(image_path)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/PIL/Image.py\", line 2843, in open\n",
            "    fp = builtins.open(filename, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'data/training_data/images/0011505151 (1).png'\n",
            "cut: the delimiter must be a single character\n",
            "Try 'cut --help' for more information.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHcNbABh4z8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "62d695b3-6b9f-4698-8e88-206a689d1f4d"
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/\"\n",
        "!pip install ."
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/unilm/layoutlm\n",
            "Processing /content/drive/My Drive/Colab Notebooks/unilm/layoutlm\n",
            "Requirement already satisfied: transformers==2.9.0 in /usr/local/lib/python3.6/site-packages (from layoutlm==0.0) (2.9.0)\n",
            "Requirement already satisfied: tensorboardX==2.0 in /usr/local/lib/python3.6/site-packages (from layoutlm==0.0) (2.0)\n",
            "Requirement already satisfied: lxml==4.5.1 in /usr/local/lib/python3.6/site-packages (from layoutlm==0.0) (4.5.1)\n",
            "Requirement already satisfied: seqeval==0.0.12 in /usr/local/lib/python3.6/site-packages (from layoutlm==0.0) (0.0.12)\n",
            "Requirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.6/site-packages (from layoutlm==0.0) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (0.1.91)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (4.48.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (2.24.0)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (0.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (1.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (2020.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/site-packages (from transformers==2.9.0->layoutlm==0.0) (3.0.12)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/site-packages (from tensorboardX==2.0->layoutlm==0.0) (3.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from tensorboardX==2.0->layoutlm==0.0) (1.15.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/site-packages (from seqeval==0.0.12->layoutlm==0.0) (2.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0->layoutlm==0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0->layoutlm==0.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0->layoutlm==0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->transformers==2.9.0->layoutlm==0.0) (1.25.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/site-packages (from sacremoses->transformers==2.9.0->layoutlm==0.0) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/site-packages (from sacremoses->transformers==2.9.0->layoutlm==0.0) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from protobuf>=3.8.0->tensorboardX==2.0->layoutlm==0.0) (49.6.0.post20200814)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (5.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (1.5.2)\n",
            "Building wheels for collected packages: layoutlm\n",
            "  Building wheel for layoutlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for layoutlm: filename=layoutlm-0.0-py3-none-any.whl size=11483 sha256=291c84a0f38b56af6f4c52b715e63c2938e5a3040ea1aa3cd413da80434575b8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-psbdvug8/wheels/18/32/63/e3fe0420420fe467f010d12e4b4af9b4b518cc3b2242a7bfb8\n",
            "Successfully built layoutlm\n",
            "Installing collected packages: layoutlm\n",
            "Successfully installed layoutlm-0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx7MMRC6L3Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "source /usr/local/etc/profile.d/conda.sh\n",
        "conda activate layoutlm"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0SK-9cIuhVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a43dad02-aac3-4ba3-f81e-ada4aef9c7f7"
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/examples/seq_labeling\"\n",
        "!python run_seq_labeling.py --data_dir data \\\n",
        "                            --model_type layoutlm \\\n",
        "                            --model_name_or_path ../layoutlm-base-uncased \\\n",
        "                            --do_lower_case \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_train \\\n",
        "                            --num_train_epochs 100.0 \\\n",
        "                            --logging_steps 10 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output \\\n",
        "                            --labels data/labels.txt \\\n",
        "                            --per_gpu_train_batch_size 16 \\\n",
        "                            --per_gpu_eval_batch_size 16 \\\n",
        "                            --fp16"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/unilm/layoutlm/examples/seq_labeling\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n",
            "Epoch:   0% 0/100 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "/usr/local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.36it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:06,  1.30it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:05,  1.37it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.43it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.47it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.51it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.55it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.56it/s]\u001b[A/usr/local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.59it/s]\n",
            "Epoch:   1% 1/100 [00:06<10:24,  6.31s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.56it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.57it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.57it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.58it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.58it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.58it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.57it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.58it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.67it/s]\n",
            "Epoch:   2% 2/100 [00:12<10:09,  6.22s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.58it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.58it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.58it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.58it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.58it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.57it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.56it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.57it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.58it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.66it/s]\n",
            "Epoch:   3% 3/100 [00:18<09:57,  6.16s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.56it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.56it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.56it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.57it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.56it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.57it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.57it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.57it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.65it/s]\n",
            "Epoch:   4% 4/100 [00:24<09:48,  6.13s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.56it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.56it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.57it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.56it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.56it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.56it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.56it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.65it/s]\n",
            "Epoch:   5% 5/100 [00:30<09:40,  6.11s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.57it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.56it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.56it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.56it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.55it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.55it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.55it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.64it/s]\n",
            "Epoch:   6% 6/100 [00:36<09:34,  6.11s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.56it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.56it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.55it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.55it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.54it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.55it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.55it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.54it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.63it/s]\n",
            "Epoch:   7% 7/100 [00:42<09:28,  6.12s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.55it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.55it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.55it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.55it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.55it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.54it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.63it/s]\n",
            "Epoch:   8% 8/100 [00:48<09:23,  6.12s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.56it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.56it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.55it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.55it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.55it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.53it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.53it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.62it/s]\n",
            "Epoch:   9% 9/100 [00:54<09:18,  6.13s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.57it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.56it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.55it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.55it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.54it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.54it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.62it/s]\n",
            "Epoch:  10% 10/100 [01:01<09:12,  6.14s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.54it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.54it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.54it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.54it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.54it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.54it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.54it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.62it/s]\n",
            "Epoch:  11% 11/100 [01:07<09:07,  6.15s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.54it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.54it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.54it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.53it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.53it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.52it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.53it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.51it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.51it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.61it/s]\n",
            "Epoch:  12% 12/100 [01:13<09:03,  6.17s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.53it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.53it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.53it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.52it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.51it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.51it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.51it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.51it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.59it/s]\n",
            "Epoch:  13% 13/100 [01:19<08:59,  6.20s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  14% 14/100 [01:26<08:56,  6.24s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  15% 15/100 [01:32<08:52,  6.27s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.48it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.48it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.48it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  16% 16/100 [01:38<08:49,  6.30s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.48it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.48it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.47it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.48it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.47it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.56it/s]\n",
            "Epoch:  17% 17/100 [01:45<08:46,  6.34s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.47it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.47it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.47it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.47it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.47it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.47it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.47it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.47it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.47it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.56it/s]\n",
            "Epoch:  18% 18/100 [01:51<08:41,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.48it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.48it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.48it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.48it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.48it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.48it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  19% 19/100 [01:58<08:36,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.48it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  20% 20/100 [02:04<08:29,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  21% 21/100 [02:10<08:22,  6.36s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  22% 22/100 [02:17<08:15,  6.35s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.51it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  23% 23/100 [02:23<08:08,  6.34s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  24% 24/100 [02:29<08:01,  6.33s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.51it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  25% 25/100 [02:36<07:54,  6.33s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.52it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.51it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.51it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  26% 26/100 [02:42<07:48,  6.33s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.52it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.52it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.51it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  27% 27/100 [02:48<07:41,  6.32s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.48it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  28% 28/100 [02:55<07:36,  6.33s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  29% 29/100 [03:01<07:30,  6.34s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  30% 30/100 [03:07<07:24,  6.34s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  31% 31/100 [03:14<07:18,  6.35s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.52it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.48it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.46it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.56it/s]\n",
            "Epoch:  32% 32/100 [03:20<07:12,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.48it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.48it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.48it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.48it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  33% 33/100 [03:26<07:06,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  34% 34/100 [03:33<07:00,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.48it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  35% 35/100 [03:39<06:53,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.49it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  36% 36/100 [03:45<06:46,  6.36s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.52it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.51it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.50it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.50it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.50it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.50it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.55it/s]\n",
            "Epoch:  37% 37/100 [03:52<06:41,  6.38s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.51it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.49it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.49it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Epoch:  38% 38/100 [03:58<06:35,  6.37s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.50it/s]\u001b[A\n",
            "Iteration:  30% 3/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  40% 4/10 [00:02<00:04,  1.50it/s]\u001b[A\n",
            "Iteration:  50% 5/10 [00:03<00:03,  1.49it/s]\u001b[A\n",
            "Iteration:  60% 6/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  70% 7/10 [00:04<00:02,  1.49it/s]\u001b[A\n",
            "Iteration:  80% 8/10 [00:05<00:01,  1.49it/s]\u001b[A\n",
            "Iteration:  90% 9/10 [00:06<00:00,  1.49it/s]\u001b[A\n",
            "Iteration: 100% 10/10 [00:06<00:00,  1.58it/s]\n",
            "Epoch:  39% 39/100 [04:05<06:28,  6.36s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 1/10 [00:00<00:06,  1.50it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:05,  1.56it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.61it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.64it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:03,  1.66it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.68it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.69it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.69it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.80it/s]\n",
            "Epoch:  40% 40/100 [04:10<06:07,  6.12s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  41% 41/100 [04:16<05:49,  5.92s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  42% 42/100 [04:21<05:35,  5.78s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  43% 43/100 [04:27<05:24,  5.68s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  44% 44/100 [04:32<05:14,  5.62s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  45% 45/100 [04:37<05:06,  5.57s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  46% 46/100 [04:43<04:58,  5.54s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  47% 47/100 [04:48<04:52,  5.52s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  48% 48/100 [04:54<04:46,  5.51s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  49% 49/100 [04:59<04:40,  5.49s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  50% 50/100 [05:05<04:34,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  51% 51/100 [05:10<04:28,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  52% 52/100 [05:16<04:22,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  53% 53/100 [05:21<04:17,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  54% 54/100 [05:27<04:11,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  55% 55/100 [05:32<04:06,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  56% 56/100 [05:38<04:00,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  57% 57/100 [05:43<03:55,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  58% 58/100 [05:49<03:49,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  59% 59/100 [05:54<03:44,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  60% 60/100 [05:59<03:38,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.70it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  61% 61/100 [06:05<03:33,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  62% 62/100 [06:10<03:28,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  63% 63/100 [06:16<03:22,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  64% 64/100 [06:21<03:16,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  65% 65/100 [06:27<03:11,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  66% 66/100 [06:32<03:06,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  67% 67/100 [06:38<03:00,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  68% 68/100 [06:43<02:55,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  69% 69/100 [06:49<02:49,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  70% 70/100 [06:54<02:44,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  71% 71/100 [07:00<02:38,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  72% 72/100 [07:05<02:33,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  73% 73/100 [07:11<02:27,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  74% 74/100 [07:16<02:22,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  75% 75/100 [07:22<02:16,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  76% 76/100 [07:27<02:11,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4063678720065206e-108\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7031839360032603e-108\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.515919680016301e-109\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.257959840008151e-109\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1289799200040754e-109\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0644899600020377e-109\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.3224498000101884e-110\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  77% 77/100 [07:33<02:06,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6612249000050942e-110\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3306124500025471e-110\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.653062250012736e-111\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.326531125006368e-111\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.663265562503184e-111\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.31632781251592e-112\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.15816390625796e-112\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.07908195312898e-112\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.03954097656449e-112\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.19770488282245e-113\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  78% 78/100 [07:38<02:00,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.598852441411225e-113\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2994262207056124e-113\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.497131103528062e-114\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.248565551764031e-114\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6242827758820155e-114\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.121413879410078e-115\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.060706939705039e-115\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0303534698525194e-115\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0151767349262597e-115\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.075883674631299e-116\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  79% 79/100 [07:44<01:55,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5379418373156492e-116\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2689709186578246e-116\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.344854593289123e-117\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1724272966445615e-117\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5862136483222808e-117\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.931068241611404e-118\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.965534120805702e-118\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.982767060402851e-118\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.913835302014255e-119\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9569176510071274e-119\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  80% 80/100 [07:49<01:49,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4784588255035637e-119\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2392294127517818e-119\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.196147063758909e-120\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0980735318794546e-120\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5490367659397273e-120\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.745183829698637e-121\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8725919148493183e-121\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9362959574246591e-121\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.681479787123296e-122\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.840739893561648e-122\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  81% 81/100 [07:54<01:44,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.420369946780824e-122\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.210184973390412e-122\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.05092486695206e-123\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.02546243347603e-123\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.512731216738015e-123\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.563656083690075e-124\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7818280418450374e-124\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8909140209225187e-124\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.454570104612593e-125\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.727285052306297e-125\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  82% 82/100 [08:00<01:38,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3636425261531484e-125\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1818212630765742e-125\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.909106315382871e-126\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9545531576914354e-126\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4772765788457177e-126\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.386382894228589e-127\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6931914471142943e-127\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8465957235571472e-127\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.232978617785736e-128\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.616489308892868e-128\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  83% 83/100 [08:05<01:33,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.308244654446434e-128\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.154122327223217e-128\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.770611636116085e-129\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8853058180580424e-129\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4426529090290212e-129\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.213264545145106e-130\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.606632272572553e-130\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8033161362862765e-130\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.016580681431383e-131\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5082903407156913e-131\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  84% 84/100 [08:11<01:27,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2541451703578456e-131\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1270725851789228e-131\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.635362925894614e-132\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.817681462947307e-132\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4088407314736535e-132\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.044203657368268e-133\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.522101828684134e-133\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.761050914342067e-133\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.805254571710335e-134\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.4026272858551673e-134\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  85% 85/100 [08:16<01:22,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2013136429275836e-134\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1006568214637918e-134\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.503284107318959e-135\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7516420536594796e-135\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3758210268297398e-135\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.879105134148699e-136\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4395525670743494e-136\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7197762835371747e-136\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.598881417685874e-137\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.299440708842937e-137\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  86% 86/100 [08:22<01:16,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1497203544214684e-137\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0748601772107342e-137\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.374300886053671e-138\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6871504430268355e-138\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3435752215134178e-138\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.717876107567089e-139\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3589380537835444e-139\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6794690268917722e-139\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.397345134458861e-140\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1986725672294305e-140\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  87% 87/100 [08:27<01:11,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0993362836147152e-140\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0496681418073576e-140\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.248340709036788e-141\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.624170354518394e-141\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.312085177259197e-141\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.560425886295985e-142\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2802129431479926e-142\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6401064715739963e-142\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.200532357869981e-143\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.100266178934991e-143\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  88% 88/100 [08:33<01:05,  5.48s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0501330894674953e-143\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0250665447337477e-143\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.1253327236687384e-144\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5626663618343692e-144\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2813331809171846e-144\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.406665904585923e-145\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2033329522929615e-145\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6016664761464807e-145\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.008332380732404e-146\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.004166190366202e-146\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  89% 89/100 [08:38<01:00,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.002083095183101e-146\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0010415475915505e-146\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0052077379577523e-147\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5026038689788762e-147\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2513019344894381e-147\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.256509672447191e-148\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1282548362235952e-148\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5641274181117976e-148\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.820637090558988e-149\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.910318545279494e-149\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  90% 90/100 [08:44<00:54,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.955159272639747e-149\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.775796363198735e-150\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.887898181599368e-150\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.443949090799684e-150\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.221974545399842e-150\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.10987272699921e-151\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.054936363499605e-151\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5274681817498023e-151\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.637340908749012e-152\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.818670454374506e-152\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  91% 91/100 [08:49<00:49,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.909335227187253e-152\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.546676135936265e-153\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7733380679681323e-153\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3866690339840662e-153\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1933345169920331e-153\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.966672584960166e-154\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.983336292480083e-154\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4916681462400413e-154\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.458340731200207e-155\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7291703656001034e-155\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.82it/s]\n",
            "Epoch:  92% 92/100 [08:55<00:43,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8645851828000517e-155\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.322925914000258e-156\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.661462957000129e-156\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3307314785000646e-156\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1653657392500323e-156\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.826828696250162e-157\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.913414348125081e-157\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4567071740625404e-157\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.283535870312702e-158\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.641767935156351e-158\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  93% 93/100 [09:00<00:38,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8208839675781755e-158\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.104419837890877e-159\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.552209918945439e-159\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2761049594727193e-159\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1380524797363597e-159\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.6902623986817984e-160\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8451311993408992e-160\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4225655996704496e-160\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.112827998352248e-161\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.556413999176124e-161\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  94% 94/100 [09:06<00:32,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.778206999588062e-161\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.89103499794031e-162\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.445517498970155e-162\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2227587494850775e-162\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1113793747425387e-162\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.556896873712694e-163\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.778448436856347e-163\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3892242184281734e-163\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.946121092140867e-164\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4730605460704336e-164\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  95% 95/100 [09:11<00:27,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7365302730352168e-164\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.682651365176084e-165\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.341325682588042e-165\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.170662841294021e-165\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0853314206470105e-165\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.426657103235053e-166\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7133285516175262e-166\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3566642758087631e-166\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.783321379043816e-167\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.391660689521908e-167\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  96% 96/100 [09:17<00:21,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.695830344760954e-167\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.47915172380477e-168\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.239575861902385e-168\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1197879309511924e-168\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0598939654755962e-168\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.299469827377981e-169\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6497349136889905e-169\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3248674568444952e-169\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.624337284222476e-170\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.312168642111238e-170\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  97% 97/100 [09:22<00:16,  5.46s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.656084321055619e-170\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.280421605278095e-171\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.140210802639048e-171\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.71it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.070105401319524e-171\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.035052700659762e-171\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.17526350329881e-172\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.587631751649405e-172\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2938158758247024e-172\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.469079379123512e-173\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.234539689561756e-173\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  98% 98/100 [09:27<00:10,  5.46s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.617269844780878e-173\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.08634922390439e-174\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.043174611952195e-174\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0215873059760975e-174\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0107936529880487e-174\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.053968264940244e-175\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.526984132470122e-175\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.263492066235061e-175\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.317460331175305e-176\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1587301655876523e-176\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch:  99% 99/100 [09:33<00:05,  5.47s/it]\n",
            "Iteration:   0% 0/10 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5793650827938261e-176\n",
            "\n",
            "Iteration:  10% 1/10 [00:00<00:05,  1.74it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.896825413969131e-177\n",
            "\n",
            "Iteration:  20% 2/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9484127069845653e-177\n",
            "\n",
            "Iteration:  30% 3/10 [00:01<00:04,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9742063534922827e-177\n",
            "\n",
            "Iteration:  40% 4/10 [00:02<00:03,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.871031767461413e-178\n",
            "\n",
            "Iteration:  50% 5/10 [00:02<00:02,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.935515883730707e-178\n",
            "\n",
            "Iteration:  60% 6/10 [00:03<00:02,  1.73it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4677579418653533e-178\n",
            "\n",
            "Iteration:  70% 7/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2338789709326767e-178\n",
            "\n",
            "Iteration:  80% 8/10 [00:04<00:01,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.169394854663383e-179\n",
            "\n",
            "Iteration:  90% 9/10 [00:05<00:00,  1.72it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.084697427331692e-179\n",
            "\n",
            "Iteration: 100% 10/10 [00:05<00:00,  1.83it/s]\n",
            "Epoch: 100% 100/100 [09:38<00:00,  5.79s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}